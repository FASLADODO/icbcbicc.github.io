<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Write your site description here. It will be used as your sites meta description as well!">

    <title>Machine Learning (Zhihua Zhou) Notes 02 - Jam's Blog</title>

    <link rel="canonical" href="http://icbcbicc.github.io/2016/10/15/machine_learning-_zhihua_zhou_notes_02/">

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="/css/bootstrap.min.css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/clean-blog.css">

    <!-- Pygments Github CSS -->
    <link rel="stylesheet" href="/css/syntax.css">

    <!-- Custom Fonts -->
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href='//fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <link type="application/atom+xml" rel="alternate" href="http://icbcbicc.github.io/feed.xml" title="Jam's Blog" />

</head>

<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript"
   src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<body>

    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">Jam's Blog</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a href="/">Home</a>
                </li>
                
				
                <li>
                    <a href="/about/">About Me</a>
                </li>
				
                
				
                <li>
                    <a href="/archives/">archives</a>
                </li>
				
                
				
                <li>
                    <a href="/contact/">Contact</a>
                </li>
				
                
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>


    <!-- Post Header -->
<header class="intro-header" style="background-image: url('/img/post-bg-07.jpg')">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading">
                    <h1>Machine Learning (Zhihua Zhou) Notes 02</h1>
                    
                    <h2 class="subheading">读书笔记</h2>
                    
                    <span class="meta">Posted by icbcbicc on October 15, 2016</span>
                </div>
            </div>
        </div>
    </div>
</header>
<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">

				<h2 id="section">3. 线性模型</h2>

<h3 id="section-1">3.2 线性回归</h3>
<ul>
  <li>
    <p>基本概念</p>

    <ul>
      <li>
        <p>线性回归：用线性模型拟合目标函数。</p>
      </li>
      <li>
        <p>均方误差：线性回归中常用的性能度量，它的几何意义是欧几里得距离(Euclidean distance)。</p>
      </li>
      <li>
        <p>最小二乘法(least square method)：基于均方误差最小化来求解模型的方法。几何意义是在目标空间中找到一个超平面，使样本点到该平面的欧式距离之和最小。</p>
      </li>
    </ul>
  </li>
  <li>
    <p>多元线性回归(multivariate linear regression)</p>

    <p>求最优$\hat{\omega}$使目标函数$E_\hat{\omega}$最小:</p>

    <script type="math/tex; mode=display">E_\hat{\omega} = (y-X\hat{\omega})^T(y-X\hat{\omega})</script>

    <p>对$\hat{\omega}$求导：</p>

    <script type="math/tex; mode=display">\frac{\partial E_{\hat{\omega}}}{\partial \hat{\omega}} = 2X^T(X\hat{\omega}-y)</script>

    <p>当$X^TX$是满秩矩阵(full-rank matrix)或正定矩阵(positive definite matrix)时，可直接求得最优解：</p>

    <script type="math/tex; mode=display">\hat{\omega} = (X^TX)^{-1}X^Ty</script>

    <p>最终模型：</p>

    <script type="math/tex; mode=display">f(x_i) = x_i^T(X^TX)^{-1}X^Ty</script>

    <p>然而当$X^TX$不是满秩矩阵时，$X$的列数多于行数，也就是特征数比样本数多。此时方程有多个最优解，需要引入正则化(regularization)来选择一个$\hat{\omega}$。</p>
  </li>
  <li>
    <p>广义线性模型(generalized linear model)</p>

    <script type="math/tex; mode=display">y = g^{-1}(\omega^Tx+b)</script>

    <p>其中，$g(.)$是单调可微函数。称之为联系函数(link function)</p>

    <p>较长用的联系函数是$ln(.)$，此时称之为对数线性回归(log-linear regression)</p>
  </li>
  <li>
    <p>对数几率回归(logistic regression)</p>

    <p>用于分类任务，将输出映射到${0,1}$的集合上。</p>

    <p><script type="math/tex">y = \frac{1}{1+e^{-(\omega^Tx+b)}}</script>
  $\to$
  <script type="math/tex">ln\frac{y}{1-y} = \omega^Tx+b</script></p>

    <p>若将$y$视为取正例的概率，则$1-y$为取反例的概率。</p>

    <p>$\frac{y}{1-y}$称为<strong>几率(odds)</strong>，反映了相对可能性。</p>

    <p>$ln\frac{y}{1-y}$称为<strong>对数几率(logit)</strong></p>

    <p>可通过<strong>极大似然法(maximum likeihood method)</strong>估计最优解：</p>

    <script type="math/tex; mode=display">l(\omega,b) = \sum_{i=1}^{m}ln\{p(y_i|x_i;\omega;b)\}</script>

    <p>$=$</p>

    <script type="math/tex; mode=display">\sum_{i=1}^{m}ln\{y_ip(y=1|x_i;\omega;b)+(1-y_i)p(y=0|x_i;\omega;b)\}</script>

    <p>$=$</p>

    <script type="math/tex; mode=display">\sum_{i=1}^{m}(-y_i(\omega;b)^Tx_i+ln(1+e^{(\omega;b)^T}x_i))</script>

    <p>此式为关于$(\omega;b)$高阶可导连续凸函数。可用<strong>梯度下降、牛顿法</strong>进行求解。</p>
  </li>
</ul>

<h3 id="linear-discriminant-analysisldafisher">3.4 线性判别分析(Linear Discriminant Analysis，LDA，亦称Fisher判别分析)</h3>

<ul>
  <li>
    <p>主要思想：将共有$N$类的样本投影到一个$N-1$维的空间，使同类的投影点接近，不同类的投影点相互远离。</p>
  </li>
  <li>
    <p>指标</p>

    <ul>
      <li>
        <p>$X_i,\mu_i,\Sigma_i$分别为第$i$类的样本点、均值向量、协方差矩阵。$\mu$为所有样本的均值向量。假设共$N$类，第$i$类有$m_i$个样本，共$m$个样本。</p>
      </li>
      <li>
        <p>全局散度矩阵：</p>
      </li>
    </ul>

    <script type="math/tex; mode=display">S_t = S_b+S_w = \sum_{i=1}^m (x_i-\mu)(x_i-\mu)^T</script>

    <ul>
      <li>类内散度矩阵：</li>
    </ul>

    <script type="math/tex; mode=display">S_w = \sum_{i=1}^N S_{w_i} = \sum_{i=1}^N \sum_{x\in X_i}(x-\mu)(x-\mu)^T</script>

    <ul>
      <li>类间散度矩阵：</li>
    </ul>

    <script type="math/tex; mode=display">S_b = S_t-S_w = \sum_{i=1}^N m_i(\mu_i-\mu)(\mu_i-\mu)^T</script>
  </li>
  <li>
    <p>优化：</p>

    <ul>
      <li>可使用$S_t,S_w,S_b$中的任意2个指标进行优化。常用的优化目标是：</li>
    </ul>

    <script type="math/tex; mode=display">max\frac{tr(W^TS_bW)}{tr(W^TS_wW)} \quad s.t. \quad W \in R^{d \times (N-1)}</script>

    <ul>
      <li>此式可以通过<strong>拉格朗日乘子法</strong>转化为广义特征值问题：</li>
    </ul>

    <script type="math/tex; mode=display">S_bW = \lambda S_wW</script>

    <ul>
      <li>$W$的闭式解：<strong>$S_w^{-1}S_b$的$N-1$个最大广义特征值所对应的特征向量</strong>组成的矩阵。</li>
    </ul>
  </li>
</ul>

<h3 id="section-2">3.5 多分类学习</h3>

<p>将多分类任务拆分为多个2分类任务</p>

<p><strong>拆分策略</strong></p>

<ul>
  <li>
    <p>一对一(One vs. One, OvO)：共$N(N-1)/2$个分类器</p>
  </li>
  <li>
    <p>一对多(One vs. Rest, OvR)：共$N$个分类器。</p>
  </li>
  <li>
    <p>多对多(Many vs. Many, MvM)</p>

    <p>用、纠错输出码(Error Correcting Output Codes, EOOC)</p>

    <ul>
      <li>
        <p>对数据进行$M$次划分，得到$M$组{训练集，测试集}，从而得到$M$个分类器。</p>
      </li>
      <li>
        <p>对每个样本，分别用$M$个分类器分类，这些预测标记组成一个编码序列。</p>
      </li>
      <li>
        <p>将预测编码与每个类别自己的编码(One-hot码)比较，距离(海明距离，欧氏距离)最近的为最终预测结果。</p>
      </li>
      <li>
        <p>EOOC对与分类器的错误有一定容忍和修正能力。</p>
      </li>
    </ul>
  </li>
</ul>

<h3 id="section-3">3.6 类别不平衡问题</h3>

<p><strong>解决方案</strong>：</p>

<ul>
  <li>
    <p>再缩放(rescaling)：$\frac{y}{1-y}&gt;\frac{m^+}{m+-}$：预测为正例。其中$m^+,m^-$分别为正例、反例的数目。</p>
  </li>
  <li>
    <p>欠采样(undersampling):去除一部分样本使得样本平衡</p>

    <p>将类别较多的样本划分为几个集合，形成多组{训练集，测试集}分别学习。虽然每组是欠采样，但全局上却没有欠采样，充分利用了数据。</p>
  </li>
  <li>
    <p>过采样(oversampling):增加一部分样本使得样本平衡</p>

    <p>不能直接对原有样本进行重复采样，否则将会出现严重的过拟合。</p>
  </li>
</ul>

<h2 id="section-4">4.决策树</h2>

<p>TODO：信息增益、增益率、基尼指数、剪枝、连续值处理、多变量决策树（斜划分）</p>


                <hr>

                <ul class="pager">
                    
                    <li class="previous">
                        <a href="/2016/10/14/machine_learning_zhihua_zhou_notes_01/" data-toggle="tooltip" data-placement="top" title="Machine Learning (Zhihua Zhou) Notes 01">&larr; Previous Post</a>
                    </li>
                    
                    
                    <li class="next">
                        <a href="/2016/10/16/machine_learning-_zhihua_zhou_notes_03/" data-toggle="tooltip" data-placement="top" title="Machine Learning (Zhihua Zhou) Notes 03">Next Post &rarr;</a>
                    </li>
                    
                </ul>

            </div>
        </div>
    </div>
</article>

<hr>


    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                    <li>
                        <a href="/feed.xml">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-rss fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    
                    <li>
                        <a href="https://github.com/icbcbicc">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li>
                        <a href="mailto:icbcbicc@hotmail.com">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-envelope fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                </ul>
                <p class="copyright text-muted">Copyright &copy; Jam's Blog 2016</p>
            </div>
        </div>
    </div>
</footer>

<!-- jQuery -->
<script src="/js/jquery.min.js "></script>

<!-- Bootstrap Core JavaScript -->
<script src="/js/bootstrap.min.js "></script>

<!-- Custom Theme JavaScript -->
<script src="/js/clean-blog.min.js "></script>

    


</body>

</html>
