<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom"><generator uri="http://jekyllrb.com" version="3.1.6">Jekyll</generator><link href="http://icbcbicc.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="http://icbcbicc.github.io/" rel="alternate" type="text/html" /><updated>2016-10-15T20:17:51+08:00</updated><id>http://icbcbicc.github.io/</id><title>Jam&#39;s Blog</title><subtitle>Write your site description here. It will be used as your sites meta description as well!</subtitle><entry><title>Machine Learning (Zhihua Zhou) Notes 02</title><link href="http://icbcbicc.github.io/2016/10/15/machine_learning-_zhihua_zhou_notes_02/" rel="alternate" type="text/html" title="Machine Learning (Zhihua Zhou) Notes 02" /><published>2016-10-15T00:00:00+08:00</published><updated>2016-10-15T00:00:00+08:00</updated><id>http://icbcbicc.github.io/2016/10/15/machine_learning _zhihua_zhou_notes_02</id><content type="html" xml:base="http://icbcbicc.github.io/2016/10/15/machine_learning-_zhihua_zhou_notes_02/">&lt;h2 id=&quot;section&quot;&gt;3. 线性模型&lt;/h2&gt;</content><author><name>icbcbicc</name></author><category term="machine learning" /><summary>3. 线性模型</summary></entry><entry><title>Machine Learning (Zhihua Zhou) Notes 01</title><link href="http://icbcbicc.github.io/2016/10/14/machine_learning_zhihua_zhou_notes_01/" rel="alternate" type="text/html" title="Machine Learning (Zhihua Zhou) Notes 01" /><published>2016-10-14T00:00:00+08:00</published><updated>2016-10-14T00:00:00+08:00</updated><id>http://icbcbicc.github.io/2016/10/14/machine_learning_zhihua_zhou_notes_01</id><content type="html" xml:base="http://icbcbicc.github.io/2016/10/14/machine_learning_zhihua_zhou_notes_01/">&lt;h1 id=&quot;section&quot;&gt;周志华《机器学习》笔记-01&lt;/h1&gt;

&lt;h2 id=&quot;section-1&quot;&gt;2. 模型的评估与选择&lt;/h2&gt;

&lt;h3 id=&quot;section-2&quot;&gt;2.1 经验误差与过拟合&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;三种误差&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;训练误差(training error)、经验误差(empirical error)&lt;/strong&gt;：训练集上的误差，受到欠拟合与过拟合的影响&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;测试误差(testing error)&lt;/strong&gt;：测试集上的误差，通过常作为泛化误差的近似&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;泛化误差(generalization error)&lt;/strong&gt;：在新样本上的误差，无法直接获得&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;欠拟合与过拟合&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;欠拟合易于克服：增加训练轮数&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;过拟合是机器学习面临的关键障碍，无法彻底避免。因为机器学习面临的问题通常是$NP$难甚至更难。然而学习算法必然要在多项式时间完成，要想彻底避免过拟合，就要通过误差最小化直接获得最优解，也就意味着$P=NP$。只要坚信$P\ne NP$，过拟合就不可避免。&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;section-3&quot;&gt;2.2 产生测试集的方法&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;2.2.1 留出法(hold-out)&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;方法：将数据集分为互斥的两个集合。采用分层采样(stratified sampling)来保证2个集合的数据分布一致性（也就是训练集和测试集中相同类型样本所占的比例相同）。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;缺陷：&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;由于单次使用留出法得到的结果不够可靠（即使保证相同类别样本比例相同，仍然有多种方式划分），一般采用多次随机划分得到多组{训练集，测试集}进行训练，误差取平均的方式。&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;训练集占的多：模型精确，但评估结果不够稳定准确；测试集占的多，模型精度不足。此问题没有完美解决方案，一般选取$\frac{2}{3}$到$\frac{4}{5}$的样本用于训练。&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;2.2.2 交叉验证法(cross validation)&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;方法：
    &lt;ol&gt;
      &lt;li&gt;先将数据划为$k$个大小相同，数据分布相同的互斥子集&lt;/li&gt;
      &lt;li&gt;每次使用$k-1$个子集进行训练，$1$个做测试。一共可获得$k$组{训练集，测试集}的组合。&lt;/li&gt;
      &lt;li&gt;&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;关键：结果的稳定性和真实性很大程度上取决于$k$的选择，因此这个方法被称作“$k$折交叉验证($k$-fold cross validation)”&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;缺陷：与留出法相似，将数据划分为$k$组有很多方式，产生了不确定因素。一般采用进行$p$次划分取均值的方法，也就是“$p$次$k$折交叉验证”，一共得到$k \times p$组{训练集，测试集}。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;特例：当$k=样本数$，称为“留一法(Leave-One-Out，LOO)”。此方式不受样本划分的影响，评估较准确，但计算量太大。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;2.2.3 自助法(bootstrapping)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;以自助采样法(bootstrapping sampling，亦称“可重复采样/有放回采样”)为基础，&lt;strong&gt;适合数据集小的情况&lt;/strong&gt; 。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;方法：在数据集$D$中有放回的随机取出一个样本，重复$m$次,得到$D’$作为训练集，$D-D’$作为测试集。$D’$中可能有重复的样本。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;当$m$足够大时，一个样本在$m$次选取中不被选中的概率是
&lt;script type=&quot;math/tex&quot;&gt;$\lim_{m \to \inf}(1-\frac{1}{m})^m \to \frac{1}{e} \approx 0.368&lt;/script&gt;$
因此$D$中有$36.8\%$的样本不在$D’$中。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;缺陷：改变了初始数据的分布。数据量足够时一般不采用此方法。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;2.2.4 调参与最终模型&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;两类参数：
    &lt;ol&gt;
      &lt;li&gt;超参数：人工设定算法的参数，数目较少&lt;/li&gt;
      &lt;li&gt;模型参数：由算法生成的参数，数量可以很多&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;在模型最优化后，应该使用所有数据（包括测试集）再训练一次，得到最终模型。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;section-4&quot;&gt;2.3 性能度量&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;2.3.2 查准率，查全率与$F$度量&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;混淆矩阵(confusion matrix)：&lt;/p&gt;

    &lt;table&gt;
      &lt;thead&gt;
        &lt;tr&gt;
          &lt;th&gt; &lt;/th&gt;
          &lt;th&gt; &lt;/th&gt;
          &lt;th&gt;预测结果&lt;/th&gt;
          &lt;th&gt; &lt;/th&gt;
        &lt;/tr&gt;
      &lt;/thead&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt; &lt;/td&gt;
          &lt;td&gt; &lt;/td&gt;
          &lt;td&gt;正例&lt;/td&gt;
          &lt;td&gt;反例&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
          &lt;td&gt;真实情况&lt;/td&gt;
          &lt;td&gt;正例&lt;/td&gt;
          &lt;td&gt;TP&lt;/td&gt;
          &lt;td&gt;FN&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
          &lt;td&gt; &lt;/td&gt;
          &lt;td&gt;反例&lt;/td&gt;
          &lt;td&gt;FP&lt;/td&gt;
          &lt;td&gt;TN&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;查准率(precision，亦称准确率)：$P = \frac{TP}{TP+FP}$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;查全率(recall，亦称召回率)：$R = \frac{TP}{TP+FN}$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;查全率与查准率通常是矛盾的&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;P-R曲线
    &lt;ul&gt;
      &lt;li&gt;方法：
        &lt;ol&gt;
          &lt;li&gt;将测试样本按概率从大到小排序&lt;/li&gt;
          &lt;li&gt;将前$n$个样本作为正例，得到查准率与查全率&lt;/li&gt;
          &lt;li&gt;$n = n+1$&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;利用P-R曲线的评估：
  &lt;img src=&quot;/img/13.png&quot; alt=&quot;P-R curve&quot; /&gt;
        &lt;ol&gt;
          &lt;li&gt;曲线下面积越大，则该模型越好。当一个曲线包住了另一个曲线而没有相交，则认为外面的曲线表示的模型更好（比如下图中的蓝色比绿色好）。&lt;/li&gt;
          &lt;li&gt;$P = R$的点称为平衡点(Break-Even Point, BEP)，也就是曲线与对角线的交点，也可作为评估依据：越大越到。&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$F_1$与$F_\beta$度量&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;F1 = \frac{2 \times P \times R}{P+R}&lt;/script&gt;
  实际上就是P与R的调和平均。&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;F_\beta = \frac{(1+\beta^2) \times P \times R}{(\beta^2 \times P) + R}&lt;/script&gt;
  实际上就是P与R的加权调和平均。$\beta$决定了查全率和查准率谁更重要：$\beta &amp;gt; 1$时，查全率更重要；$0 &amp;lt; \beta &amp;lt; 1$时，查准率更重要。&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;宏查准率，宏查全率，宏$F1$；微查准率，微查全率，微$F1$：略&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;2.3.3 ROC与AUC&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;截断点(cut point)的选择：&lt;/p&gt;

    &lt;p&gt;将样本按概率从大到小排序&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;查准率高：截断点靠前&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;查全率高：截断点靠后&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;ROC(Receiver Operating Characteristic，受试者工作特征)
  &lt;img src=&quot;/img/14.png&quot; alt=&quot;ROC curve&quot; /&gt;&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;纵轴：真正率
  &lt;script type=&quot;math/tex&quot;&gt;TPR = \frac{TP}{TP+FN}&lt;/script&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;横轴：假正率
  &lt;script type=&quot;math/tex&quot;&gt;FPR = \frac{FP}{TN+FP}&lt;/script&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;对角线：随机猜测模型&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;评估方式：与P-R曲线相同。曲线下的面积称为AUC（Aera under ROC）&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;2.3.4 代价敏感错误率与代价曲线&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;之前的评价方式隐式假设了均等代价，即将错误个数作为代价。在非均等代价下，ROC曲线不能反映出总体代价，此时应该使用代价曲线。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;代价曲线(cost surve)&lt;/strong&gt;
  &lt;img src=&quot;/img/15.png&quot; alt=&quot;cost curve&quot; /&gt;
    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;横轴：正例概率代价
  &lt;script type=&quot;math/tex&quot;&gt;P(+)cost = \frac{p \times cost_{01}}{p \times cost_{01}+(1-p) \times cost_{10}}&lt;/script&gt;
其中，$p$为正例的概率；$cost_{01}$为假反率代价；$cost_{10}$为假正率代价。&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;纵轴：归一化代价
  &lt;script type=&quot;math/tex&quot;&gt;cost_{norm} = \frac{(1-TPR) \times p \times cost_{01}+FPR \times (1-p) \times cost_{10}}{p \times cost_{01}+(1-p) \times cost_{10}}&lt;/script&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;在ROC曲线上取一点(FPR, TPR)，在代价曲线上将左纵轴上的(0,FPR)与右纵轴上的(1，1-TPR)2点连成线段。所有线段围成的部分面积为&lt;strong&gt;期望总体代价&lt;/strong&gt;。&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;section-5&quot;&gt;2.4 比较检验&lt;/h3&gt;
&lt;p&gt;用于度量模型在测试集上的性能有多大概率是泛化性能，暂略&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2.4.1 假设检验&lt;/strong&gt;
&lt;strong&gt;2.4.2 价差验证t检验&lt;/strong&gt;
&lt;strong&gt;2.4.3 McNemar检验&lt;/strong&gt;
&lt;strong&gt;2.4.4 Friedman检验与Nemenyi后续检验&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;section-6&quot;&gt;2.5 偏差与方差&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;基于均方误差的回归任务的泛化误差可分解为偏差、方差、噪声之和&lt;/strong&gt;。&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;偏差：标记与真实类别的偏差。表明了在当前任务上任何学习算法所能达到的期望泛化误差的最小值，是任务本身的属性。&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;方差：同样大小的训练集变化所导致的性能变化，即数据扰动造成的影响。&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;偏差：算法本身的拟合能力。&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;偏差-方差窘境(bias-variance dilemma)&lt;/p&gt;

    &lt;p&gt;偏差与方差一般都是冲突的。&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;训练刚开始：拟合能力不足，受数据扰动的影响较小。偏差主导了泛化错误率。&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;训练充足：拟合能力很强，受数据扰动的影响大。方差主导了泛化错误率。&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Attention：对于分类任务，由于0/1损失函数的跳变性，偏差-方差分解很困难。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>icbcbicc</name></author><category term="machine learning" /><summary>周志华《机器学习》笔记-01</summary></entry><entry><title>Online Detection of Abnormal Events Using Incremental Coding Length</title><link href="http://icbcbicc.github.io/2016/10/04/Online-Detection-of-Abnormal-Events-Using-Incremental-Coding-Length/" rel="alternate" type="text/html" title="Online Detection of Abnormal Events Using Incremental Coding Length" /><published>2016-10-04T00:00:00+08:00</published><updated>2016-10-04T00:00:00+08:00</updated><id>http://icbcbicc.github.io/2016/10/04/Online Detection of Abnormal Events Using Incremental Coding Length</id><content type="html" xml:base="http://icbcbicc.github.io/2016/10/04/Online-Detection-of-Abnormal-Events-Using-Incremental-Coding-Length/">&lt;h1 id=&quot;online-detection-of-abnormal-events-using-incremental-coding-length&quot;&gt;Online Detection of Abnormal Events Using Incremental Coding Length&lt;/h1&gt;

&lt;p&gt;Authors: &lt;em&gt;Jatanta K.Dutta, Bonny Banerjee&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://pdfs.semanticscholar.org/83f6/d84389dcdc25a4a1462044d7b1cbc2e75eac.pdf&quot;&gt;PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;本文使用稀疏编码进行异常事件检测。数据预处理、特征提取、稀疏编码、字典生成都使用传统方法。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;创新之处在于引进了 Incremental Coding Length (ICL)作为稀疏表达的评价，它代表了每个特征的熵的增加量。异常事件可以由特征的rarity来定义（罕见的特征意味着异常）。最终，将所有特征的energy按权重相加就可以判断是否有异常了。文中将每一个特征的energy作为rarity， 它是关于ICL的函数。ICL的计算不需要任何参数，也不需要关于数据的先验假设&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;abstract&quot;&gt;1. Abstract&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;事件的异常主要是由2个因素同时决定的:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;在稀疏表达事件的过程中，每个特征使用的频率&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;稀疏表达中特征的系数&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;2. Introduction&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;异常事件的检测面临3个难点：&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;无监督的2分类&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;数据量大，无法全部存储&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;数据的分布不恒定&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;related-work&quot;&gt;3. Related Work&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;异常事件检测通常由以下几个步骤组成（以及其常用方法）：&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;数据预处理，获得低级表达&lt;/em&gt;
    &lt;ul&gt;
      &lt;li&gt;histogram of optical flow (HOF)&lt;/li&gt;
      &lt;li&gt;spatiotemporal gradient&lt;/li&gt;
      &lt;li&gt;social force model&lt;/li&gt;
      &lt;li&gt;chaotic invariant&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;对低级表达进行抽象，得到中级表达
    &lt;ul&gt;
      &lt;li&gt;dimensionality reduction(PCA, ICA, clustering)&lt;/li&gt;
      &lt;li&gt;sparse coding&lt;/li&gt;
      &lt;li&gt;gaussian mixture model&lt;/li&gt;
      &lt;li&gt;mixtures of dynamic textures&lt;/li&gt;
      &lt;li&gt;hiden Markov model&lt;/li&gt;
      &lt;li&gt;Markov random field&lt;/li&gt;
      &lt;li&gt;latent Dirichlet allocation&lt;/li&gt;
      &lt;li&gt;deep learning&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;对这些表达进行评估，检测出异常（本文所关注的重点）
    &lt;ul&gt;
      &lt;li&gt;reconstruction error&lt;/li&gt;
      &lt;li&gt;prediction error&lt;/li&gt;
      &lt;li&gt;rarity index&lt;/li&gt;
      &lt;li&gt;information content&lt;/li&gt;
      &lt;li&gt;density-based scoring&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;proposed-framework&quot;&gt;4. Proposed Framework&lt;/h2&gt;

&lt;h3 id=&quot;video-representation&quot;&gt;4.1 Video Representation&lt;/h3&gt;

&lt;p&gt;Spatiotemporal interest point detector&lt;/p&gt;

&lt;h3 id=&quot;online-sparse-dictionary-learning&quot;&gt;4.3 Online Sparse Dictionary Learning&lt;/h3&gt;

&lt;p&gt;Batch Orthogonal Matching Pursuit （Batch OMP）&lt;/p&gt;

&lt;h3 id=&quot;abnoraml-event-detection&quot;&gt;4.3 Abnoraml Event Detection&lt;/h3&gt;

&lt;p&gt;假设对某一时刻的输入数据$X(t) = [x_1(t), …, x_n(t)]$，都有稀疏系数 $\Gamma = [\gamma_1, … , \gamma_n] \in R^{k*n}$&lt;/p&gt;

&lt;p&gt;那么在时刻$t$，对于第 $j$ 个特征的 activity ratio 定义为：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p_j(t) = \frac{\sum_{h=1}^n|\Gamma_{j,h}(t)|}{\sum_{i=1}^k\sum_{h=1}^n|\Gamma_{i,h}(t)|}&lt;/script&gt;

&lt;p&gt;$t$ 时刻的 summary activity ratio 将按照以下方式更新（初始值为$1/k$）：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;q(t) = (1-\alpha(t))q(t-1)+\alpha(t)p(t)&lt;/script&gt;

&lt;p&gt;其中，$\alpha(t)$ 是一个时间的函数。当 $\alpha(t) = 1/t$ , $q(t)$ 就是从开始到现在的平均 activity ratio。当$\alpha(t) = 1/t_1$时， （$t_1$ 是一个正的常数）, $q(t)$ 就是前 $t_1$ 个 activity ratio 的平均值。$\alpha(t) = 1/t_1$ 对于数据分布不稳定的情况很有用。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;ICL(q_j) = \frac{\partial {H(q)} }{\partial {q_j} } = -H(q) - q_j - log q_j - q_j log q_j&lt;/script&gt;

&lt;p&gt;在计算完 ICL 后，就得到了任意 $t$ 时刻的显著特征集（salient feature set）&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;S(t) = \{j | ICL(q_j(t)) &gt; 0\}&lt;/script&gt;

&lt;p&gt;$S(t)$ 中的每一个显著特征的energy表示为：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\theta_j(t) = \frac{ICL(q_j(t))}{\sum_{i \in S(t)}ICL(q_i(t))} \quad s.t. \quad j \in S(t)&lt;/script&gt;

&lt;p&gt;对于不属于$S(t)$的特征：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\theta_j(t) = 0 \quad s.t. \quad j \notin S(t)&lt;/script&gt;

&lt;p&gt;$\theta_j(t)$ 表示了用$j$特征来表示输入的罕见程度&lt;/p&gt;

&lt;p&gt;最终，每一个cube的 anomaly score 定义为：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;g = |\gamma|^T\theta&lt;/script&gt;

&lt;p&gt;将连续几帧的所有 cube 的 anomaly score 经过 gaussian filter 处理作为每一帧的 anomaly map&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;experimental-result&quot;&gt;5. Experimental Result&lt;/h2&gt;

&lt;p&gt;略&lt;/p&gt;</content><author><name>icbcbicc</name></author><summary>Online Detection of Abnormal Events Using Incremental Coding Length</summary></entry><entry><title>The Negative —— Part 2</title><link href="http://icbcbicc.github.io/2016/10/02/The-Negative-Part-2/" rel="alternate" type="text/html" title="The Negative —— Part 2" /><published>2016-10-02T00:00:00+08:00</published><updated>2016-10-02T00:00:00+08:00</updated><id>http://icbcbicc.github.io/2016/10/02/The Negative Part 2</id><content type="html" xml:base="http://icbcbicc.github.io/2016/10/02/The-Negative-Part-2/">&lt;h2 id=&quot;section&quot;&gt;4. 区域选置&lt;/h2&gt;

&lt;p&gt;由于区域选置这一概念是基于其他重要概念之上的，因此我们先介绍一些基本概念。&lt;/p&gt;</content><author><name>icbcbicc</name></author><summary>4. 区域选置</summary></entry><entry><title>The Negative —— Part 1</title><link href="http://icbcbicc.github.io/2016/10/01/The-Negative-Part-1/" rel="alternate" type="text/html" title="The Negative —— Part 1" /><published>2016-10-01T00:00:00+08:00</published><updated>2016-10-01T00:00:00+08:00</updated><id>http://icbcbicc.github.io/2016/10/01/The Negative Part 1</id><content type="html" xml:base="http://icbcbicc.github.io/2016/10/01/The-Negative-Part-1/">&lt;h2 id=&quot;section&quot;&gt;1. 简介&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;最终目标:&lt;/strong&gt; 视觉化&lt;/p&gt;

&lt;p&gt;（摄影的）的工艺与技术尽管很重要，但它们永远是屈从于摄影师的表达观念的。换句话说，它们是必须的而不是主要的。&lt;/p&gt;

&lt;p&gt;有一点值得注意的是：摄影的表达，或者说摄影的创意与现实是没有直接的关系的。我们不会将观察到的事物的内在价值直接复制到照片中。但我们会模仿这些价值，或者将他们呈现在它相关的感情中。很多人认为我的照片是“写实”的。实际上，他们所谓的“现实”只是他们认为自己眼中图像是准确的，这种“现实”是是绝对偏离了真正的现实的。之所以观看者会认为我的作品是写实的，是因为作品的视觉效果很合理和可信。如果将我的作品与其中所表现的事物拿出来直接对比，就会显现出巨大的视觉差异。&lt;/p&gt;

&lt;p&gt;要实现令人满意的视觉化，关键在于在底片上体现合适的信息。&lt;/p&gt;

&lt;p&gt;实现视觉化的第一步是 &lt;strong&gt;图像管理&lt;/strong&gt;，这在此系列的第一本书（&lt;em&gt;The Camera&lt;/em&gt;）中有详细阐述，它涉及到你的观念和相机的调整。在这本书中我们将要讨论 &lt;strong&gt;图像值&lt;/strong&gt; 的控制。它是通过曝光、冲洗和其他一些因素决定的。当然，因为我们的最终目标是得到相片（正像），所以我们会根据最终的正像来讨论负片的控制。第三本书（&lt;em&gt;The Print&lt;/em&gt;）将详细地阐述得到正像和放大的过程。&lt;/p&gt;

&lt;p&gt;尽管我们分不同阶段阐述了视觉化和相关技术，但在实际操作中，我们应该一开始就把整个过程当作以一个整体来考虑。摄影是一个复杂、流动的介质，它的很多因素都不是按顺序执行的，就像杂耍艺人在抛球时要保持几个球同时在空中一样。&lt;/p&gt;

&lt;p&gt;自从1940年以来，分区系统就已经应用在摄影中。它被人们支持过也被反对过。它也有很多种不同的解释方式，但不是所有的解释都是正确的，因为这些解释与感光的原理相矛盾。现在我用的分区系统的值的范围是0到10（原文使用罗马数字，为方便书写，在此使用阿拉伯数字替代），0代表纯黑，10代表纯白。实际上，我们一般使用1和9作为真实亮度的极限，这个范围包含了所有的纹理与元素。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;2. 了解光线&lt;/h2&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;2.1 人类的视觉与摄影&lt;/h3&gt;

&lt;p&gt;制作一副高质量的黑白影像，关键在于学会预想彩色场景转化为黑白之后的效果。因此，研究人眼感知能力与摄影捕捉图像的能力之间所存在的差异很重要。人眼所能感知的影调范围比胶片所能记录的范围大得多。人的视觉系统能够接受1000000：1的动态范围，这让人眼可以在深夜或者阳光直射之下看清纸上的字。这意味着我们能够看到20档的动态范围。然而在胶片上，只能捕捉1000：1的动态范围，也就是10档的影调范围。区域系统理论的一个主要目的就是调整胶片的动态范围。&lt;/p&gt;

&lt;p&gt;相比摄影，人眼还具有“色彩自适应”的优点——比如我们看到阴影中的一座白色的房子，虽然它呈现出灰色，但我们还是会把他看成“白色”。然而胶片就没有这种功能，它只能保持动态范围不变。运用区域系统理论进行拍摄与显影，就能使得照片中的景象和看到的一样。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;section-3&quot;&gt;2.2 光线的性质&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;反射光&lt;/strong&gt;&lt;br /&gt;
室外场景中，大部分光线都是反射光。被摄对象的材质（光滑程度、颜色深浅）和光线的入射角度都会影响胶片对它的记录。比如白色的墙壁能够将光线反射到其他物体上从而提亮阴影，减少反差。反之，一排影调较深的树木则会吸收环境光，保持阴影不被体谅，从而增加反差。&lt;/p&gt;

    &lt;p&gt;光线都有色彩倾向，它会对反射光的强度造成一定的影响。比如，在日出或者日落时光线偏红，因此绿色物体的反射光就会减弱。同样，阴影处的光线就会偏蓝，并且减少对黄色或者红色物体的反射率。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;直射光&lt;/strong&gt;&lt;br /&gt;
当某一光源的位置相聚拍摄对象较远时，或者被摄对象相对较小时，所产生的是直射光（硬光）。这种光线会产生较强的反差（明亮的高光与边缘清晰的阴影）&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;漫射光&lt;/strong&gt;&lt;br /&gt;
漫射光所产生的阴影相比直射光更加柔和甚至消失。柔光箱可以制造漫射光源，但如果它离被摄物体较远，就达不到效果。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;要注意的是，光线的性质与光线的强度没有直接的关系。&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Sweet Light&lt;/strong&gt;&lt;br /&gt;
这种光线只存在于日出前的半个小时到一个小时，和日落后的半个小时到一个小时。其时间长短取决于天气的情况。尽管这是一种漫射光，但他的反差范围很大。天空中最明亮的区域位于地平线附近，光线缺乏方向性，会着照亮很多阴影。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-4&quot;&gt;3. 分区尺标&lt;/h2&gt;

&lt;p&gt;分区尺标是区域系统的标志性元素，他也被称做灰阶或区域尺。它是由一系列连续变化的11个影调组成的，分别标记为0区到10区（纯黑到纯白）。分区尺标可以分为3个人部分：暗部区域（0，1，2）、细节区域、高光区域。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/11.JPG&quot; alt=&quot;灰阶&quot; /&gt;&lt;/p&gt;

&lt;p&gt;以下是几个对影像特征的描述：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;影纹&lt;/strong&gt;：能感受到影调的变化，但是没有图像信息&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;微弱的细节&lt;/strong&gt;：包含信息较少&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;肌理&lt;/strong&gt;：具有一定锐度的重复的影调变化&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;清晰的细节&lt;/strong&gt;：丰富的信息&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-5&quot;&gt;3.1 暗部区域（0-1 区）&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;0区（纯黑）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;对于负片来说，就是没有可用密度。然而并没有一个硬性的规定，要求0区必须占多少比例。黑色为照片的动态范围建立了基础。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;1区（近似于纯黑）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这一区域的影调与0区很难区分，在没有0区的对比下，很容易将其误认为0区。这一点是胶片特性曲线直线段的起点，从这个区开始，每增加一档曝光，密度也会增加一个区。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/12.JPG&quot; alt=&quot;胶片与相纸的特性曲线&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;2区（有影纹的暗部）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;2区是除了表现影调之外还能提供图像信息的最暗的区，它大约有5%的反射率。因为2区位于胶片特征曲线的直线段，所以它是第一个始终可以进行“选置”的区。我们可以用反射式测光表读出数据，在此基础上降低3档曝光来获得2区的曝光参数。&lt;/p&gt;

&lt;h4 id=&quot;section-6&quot;&gt;3.2 细节区域（3-7 区）&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;3区（暗部细节）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;它是我们能看到清晰细节的区域中影调最深的一个。3区确定了影像的基调。3区是确认正确曝光的基本标准。因为如果在曝光时没有在底片上记录下暗部细节，那么无论怎样显影都不会呈现任何影像。因此，我们通常将3区作为暗部测光法的测量区域，也可以作为平均测光法的暗部测光区域。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;4区（影调较深的中灰区域）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;4区是暗部过度到亮部的起始区。它与6区这两个过渡区对于照片的反差起到了决定性的作用。如果过渡区变小，反差就会较大。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;5区（中灰区域）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;它位于整个影调区域的正中间，并处在倒易律范围（2-8区）。5区能反射照射在该区域上的约18%的光线&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;6区（较浅的中灰区）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;它是中间影调向高光区过渡的起始区域。6区是高调影像的基础。当拍摄白人肖像时，可以对其手掌测光获得曝光数值&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;7区（表现高光区域中的细节）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;7区是细节区域中最亮的一个区域，有将近72%的反射率。如果图像大部分都落在这一区域，图像就会很柔美、明亮与轻盈。它被作为平均测光法的亮部测光区。在暗室印放过程中，7区也是检验影响密度是否合适的目标区。因为7区以上的区域的密度变化会受到胶片曲线肩部的影像，形成更宽的影调范围。&lt;/p&gt;

&lt;h4 id=&quot;section-7&quot;&gt;3.3 高光区域（8-10区）&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;8区（有影纹的高光区域）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;8区是最亮的仍然包含有影像信息的区域，8区以上的区域之间已经不再是线性关系。但在测光表读数的基础上增加3档曝光则会精确地落在8区。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;9区（接近纯白）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;只有将10区与9区放在一起才能区分两者。9区位于曲线地肩部终点，也就是说如果测量一张照片的9区，会达到最低密度&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;10区（纯白）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;纸基的白度决定了10区的效果。但在后期处理照片时，很容易污染纯白的相纸。比如安全灯会在相纸上形成轻微的灰雾，过度冲洗会减少氧化钡图层。化学污渍，不完全定影与纸基干燥后影调变深，都会造成照片高光区域的动态范围损失。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;center&gt;============ 接 Part 2 =============&lt;/center&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>icbcbicc</name></author><summary>1. 简介</summary></entry><entry><title>Online Learning for Matrix Factorization and Sparse Coding</title><link href="http://icbcbicc.github.io/2016/09/21/Online-Learning-for-Matrix-Factorization-and-Sparse-Coding/" rel="alternate" type="text/html" title="Online Learning for Matrix Factorization and Sparse Coding" /><published>2016-09-21T00:00:00+08:00</published><updated>2016-09-21T00:00:00+08:00</updated><id>http://icbcbicc.github.io/2016/09/21/Online Learning for Matrix Factorization and Sparse Coding</id><content type="html" xml:base="http://icbcbicc.github.io/2016/09/21/Online-Learning-for-Matrix-Factorization-and-Sparse-Coding/">&lt;h1 id=&quot;online-learning-for-matrix-factorization-and-sparse-coding&quot;&gt;Online Learning for Matrix Factorization and Sparse Coding&lt;/h1&gt;
&lt;p&gt;Authors: &lt;em&gt;Julien Mairal, Francis Bach, Jean Ponce, Guillermo Sapiro&lt;/em&gt;&lt;br /&gt;
&lt;a href=&quot;http://www.jmlr.org/papers/volume11/mairal10a/mairal10a.pdf&quot;&gt;PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/b5dfacb7-b178-4002-823e-fc5dcfd2d641.png&quot; alt=&quot;mindmap&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;1. Introduction&lt;/h2&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Linear decompositon of a matrix using learned dictionary instead of pre-defined one&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Usage:&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;low-level: image denoising, texture synthesis, audio processing&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;high-level: image classification&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Differences between maxtrix factorization and PCA:&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;It doesn’t impose that the basis vector to be orthogonal&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Allowing more flexibility to adapt the representation to the data&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Variants matrix factorization problem:&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Non-negtive matrix factorization&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Sparse PCA&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;problem-statement&quot;&gt;2. Problem Statement&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Optimize the &lt;strong&gt;&lt;em&gt;empirical cost function:&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;f_n(D) = \frac{1}{n}\sum_{i=1}^n l (x_i,D)&lt;/script&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;$D\in R^{m * k}$ :dictionary&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;$m &amp;lt; &amp;lt; n$: feature nums less than sample nums&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;$k &amp;lt; &amp;lt; n$: atom nums of dictoinary less than sample nums&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;$k &amp;gt; m$: &lt;strong&gt;&lt;em&gt;Overcomplete dictionary&lt;/em&gt;&lt;/strong&gt;: atoms more than feature nums&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$l_1$ sparse coding problem (&lt;strong&gt;&lt;em&gt;basis pursuit&lt;/em&gt;&lt;/strong&gt;):&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;l_1(x,D) = min\frac{1}{2}{\|x-D\alpha\|}_2^2+\lambda\|\alpha\|_1 \quad s.t. \quad \alpha \in R^k&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Disadvantage:&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;There is no direct analytic link between the value of $\lambda$ and the corresponding effective sparsity $|\alpha|_0$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Solution:&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;To prevent $D$ from having arbitrarily large values (which would lead to arbitrarily small values of $\alpha$), it is common to &lt;strong&gt;&lt;em&gt;constrain its columns $d_1, . . . ,d_k$ to have an $l_2-norm$&lt;/em&gt;&lt;/strong&gt; less than or equal to 1&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;C = \{D \in R^{m * k}\quad s.t. \quad \forall j=1, ... ,k \quad d_j^Td_j \le 1\}&lt;/script&gt;

    &lt;p&gt;It’s a joint optimization problem with respet to $D$ and $\alpha=[\alpha_1, …, \alpha_k] \in R^{k * n}$, which is &lt;strong&gt;&lt;em&gt;not jointly convex&lt;/em&gt;&lt;/strong&gt; but &lt;strong&gt;&lt;em&gt;convex with respect to each of the two variables&lt;/em&gt;&lt;/strong&gt; $D$ and $\alpha$ when the other one is fixed&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Optimization method:&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;&lt;em&gt;Alternate between the two variables&lt;/em&gt;&lt;/strong&gt;, minimizing over one while keeping the other one fixed&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Since the computation of $\alpha$ dominates the cost of each iteration in this &lt;strong&gt;&lt;em&gt;block-coordinate descent&lt;/em&gt;&lt;/strong&gt; approach, a &lt;strong&gt;&lt;em&gt;second-order optimization&lt;/em&gt;&lt;/strong&gt; technique can be used to accurately estimate $D$ at each step when $\alpha$ is fixed&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;em&gt;Stochastic gradient&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;Its rate of convergence is very poor in conventional optimization terms, may in fact in certain settings &lt;strong&gt;&lt;em&gt;to be faster in reaching a solution with low expected cost than second-order batch&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Dictionary learning:&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;The classical &lt;strong&gt;&lt;em&gt;projected first-order projected stochastic gradient descent&lt;/em&gt;&lt;/strong&gt; consists of a sequence of updates of $D$&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;D_t = \prod [{D_{t-1}-\delta_t \nabla_C l(x_t,D_{t-1})}]&lt;/script&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;$\nabla_C: \quad$ Orthogonal projector onto $C$&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;$x_t: \quad$ i.i.d samples obtained by cycling on a randomly permuted training set&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;$\delta_t: \quad$ learning rate(good results are obtained using  $\delta_t = \frac{a}{t+b}$ where $a$ and $b$ are chosen depended on the training data)&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;online-dictionary-learning&quot;&gt;3. Online Dictionary Learning&lt;/h2&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;algorithm-outline&quot;&gt;3.1 Algorithm Outline&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Assuming that the training set is composed of &lt;strong&gt;&lt;em&gt;i.i.d. samples&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;script type=&quot;math/tex; mode=display&quot;&gt;f_t(D) = \frac{1}{t}\sum_{i=1}^t l (x_i,D)&lt;/script&gt;

    &lt;p&gt;and&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{f_t}(D) = \frac{1}{t}\sum_{i=1}^t(\frac{1}{2}\|x_i-D\alpha_i\|_2^2+\lambda\|\alpha_i\|_1)&lt;/script&gt;

    &lt;p&gt;&lt;strong&gt;&lt;em&gt;converge almost surely to the same limit&lt;/em&gt;&lt;/strong&gt;, and thus that $\hat{f_t}$ acts as a surrogate for $f_t$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Since $\hat{f_t}$ is close to $\hat{f_{t-1}}$ for large values of $t$, so are $D_t$ and $D_{t−1}$, use $D_{t−1}$ as &lt;strong&gt;&lt;em&gt;warm restart&lt;/em&gt;&lt;/strong&gt; for computing $D_t$ can acceerate this algorithm&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;sparse-coding&quot;&gt;3.2 Sparse Coding&lt;/h4&gt;

&lt;p&gt;This is a &lt;strong&gt;&lt;em&gt;$l_1$ regularized linear least-squares problem :&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;l_1(x,D) = min\frac{1}{2}{\|x-D\alpha\|}_2^2+\lambda\|\alpha\|_1 \quad s.t. \quad \alpha \in R^k&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Traditional method&lt;/strong&gt; (&lt;strong&gt;&lt;em&gt;Coordinate descent with soft thresholding&lt;/em&gt;&lt;/strong&gt;)&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;It is efficient when the columns of the dictionary are &lt;strong&gt;&lt;em&gt;low correlated&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;Problem:&lt;/strong&gt; The columns of learned dictionaries are in general &lt;strong&gt;&lt;em&gt;highly correlated&lt;/em&gt;&lt;/strong&gt;, which make this method rather slow&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;New method&lt;/strong&gt; (&lt;strong&gt;&lt;em&gt;LARS-Lasso algorithm&lt;/em&gt;&lt;/strong&gt;)&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;With an efficient Cholesky-based implementation, it is at least as fast as the one above&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;It provides the solution with a &lt;strong&gt;&lt;em&gt;higher accuracy&lt;/em&gt;&lt;/strong&gt; and being more robust since it does not require an arbitrary stopping criterion&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/img/9.JPG&quot; alt=&quot;Sparse Coding&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;dictionary-update&quot;&gt;3.3 Dictionary Update&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/img/10.JPG&quot; alt=&quot;Dictionary update&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;The procedure does not require to store all the vectors $x_i$ and $\alpha_i$, but only $A_t$ and $B_t$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Sequentially updates each column of $D$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Orthogonal projection on to $C$(the constraint set)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;In practice, the matrix $A_t$ are often &lt;strong&gt;&lt;em&gt;concentrated on the diagonal&lt;/em&gt;&lt;/strong&gt;, which makes the block-coordinate descent more efficient&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;optimizing-the-algorithm&quot;&gt;3.4 Optimizing the Algorithm&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;em&gt;3.4.1&lt;/em&gt;&lt;/strong&gt; Handling fixed-size data sets&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;&lt;em&gt;Problem:&lt;/em&gt;&lt;/strong&gt; When the data sets are predefined and have finite size, the same data points may be examined several times&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;&lt;em&gt;Solution:&lt;/em&gt;&lt;/strong&gt; When the training set is small enough, it is possible to further speed up convergence:&lt;/p&gt;

        &lt;p&gt;If the sample $x$ has been drawn from the data sets twice in the iteration $t_0$ and $t$, we will replace $\alpha_{t_0}$ by $\alpha_t$ in $A_t$ and $B_t$, that is&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;A_t = A_{t-1} + \alpha_t\alpha_t^T - \alpha_{t_0}\alpha_{t_0}^T&lt;/script&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;B_t = B_{t-1} + x_t\alpha_t^T - x_t\alpha_{t_0}^T&lt;/script&gt;

        &lt;p&gt;In this setting, we need to store $\alpha_i$ in every iteration and it’s &lt;strong&gt;&lt;em&gt;impractical&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

        &lt;p&gt;However, we can sovle this by removing the information from $A_t$ and $B_t$ that is older than two epochs(cycles through the data)&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;em&gt;3.4.2&lt;/em&gt;&lt;/strong&gt; Scaling te past data&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;&lt;em&gt;Problem:&lt;/em&gt;&lt;/strong&gt; At each iteration, the “new” information $\alpha_t$ that is added to $A_t$ and $B_t$ has the same weight as the “old” one&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;&lt;em&gt;Solution:&lt;/em&gt;&lt;/strong&gt; Rescaling the “old” information so that newer coefficients $\alpha_t$ have more weight, which is classical in online learning&lt;/p&gt;

        &lt;p&gt;We propose to replace lines 5 and 6 of Algorithm 1 by:&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;A_t = \beta_t A_{t-1} + \alpha_t\alpha_t^T&lt;/script&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;B_t = \beta_t B_{t-1} + x_t\alpha_t^T&lt;/script&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;\beta_t = (1-\frac{1}{t})^\rho&lt;/script&gt;

        &lt;p&gt;In this circumstance, we propose&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;D_t = argmin_{D \in C}\frac{1}{\sum_{j=1}^t(j/t)} \sum_{i=1}^t(\frac{i}{t})^\rho(\frac{1}{2}\|x_i-D\alpha_i\|_2^2+\lambda\|\alpha_i\|_1)&lt;/script&gt;

        &lt;p&gt;=&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;argmin_{D \in C}\frac{1}{\sum_{j=1}^t(j/t)}(\frac{1}{2}Tr(D^TDA_t)-Tr(D^TB_t))&lt;/script&gt;

        &lt;p&gt;When $\rho = 0$, we obtain the original version of the algorithm&lt;/p&gt;

        &lt;p&gt;&lt;strong&gt;&lt;em&gt;In practice, this parameter $\rho$ is only useful for large data sets $(n \ge 100000)$&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;em&gt;3.4.3&lt;/em&gt;&lt;/strong&gt; Mini-batch extension&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;The complexity of computing $\eta$ vectors $\alpha_i$ is not linear in $\eta$&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;A &lt;strong&gt;&lt;em&gt;Cholesky-based implementation of LARS-Lasso&lt;/em&gt;&lt;/strong&gt; for decomposing one signal has a complexity of $O(kms+ks^2)$, where $s$ is the number of nonzero coefficient&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;When decomposing $\eta$ signals, it is possible to &lt;strong&gt;&lt;em&gt;pre-compute the Gram matrix $D^T_tD_t$&lt;/em&gt;&lt;/strong&gt; and the total complexity becomes $O(k^2m+\eta(km+ks^2))$, which is much cheaper than $\eta$ times the previous complexity when $\eta$ is large enough and $s$ is small&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;We propose to replace lines 5 and 6 of Algorithm 1 by:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;A_t = A_{t-1} + \frac{1}{\eta}\sum_{i=1}^\eta \alpha_{t,i} \alpha_{t,i}^T&lt;/script&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;B_t = B_{t-1} + \frac{1}{\eta}\sum_{i=1}^\eta x_{t,i}\alpha_{t,i}^T&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;em&gt;3.4.4&lt;/em&gt;&lt;/strong&gt; Slowing down the first iterations&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;&lt;em&gt;Problem:&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;The first iterations of our algorithm may update the parameters with large steps, immediately leading to large deviations from the initial dictionary&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;&lt;em&gt;solution:&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;Use gradient steps of the form $\frac{a}{b+t}$&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;$b$ will slow down the first few steps&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;An initialization of the form $A_0 = t_0I$ and $B_0 = t_0 D_0$ with $t_0 \ge 0$ will also slow down the first steps&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;em&gt;3.4.5&lt;/em&gt;&lt;/strong&gt; Puring the dictionary from unused atoms&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;&lt;em&gt;Problem:&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;Some of the dictionary atoms are never (or very seldom) used, which typically happens with a very bad initialization&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;&lt;em&gt;solution:&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;In general cases, replacing these atoms during the optimization by randomly chosen elements of the training set&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;For more difficult and highly regularized cases, choosing a continuation strategy consisting of starting from an easier, less regularized problem, and gradually increasing $\lambda$&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;link-with-second-order-stochastic-gradient-descent&quot;&gt;3.5 Link with Second-order Stochastic Gradient Descent&lt;/h4&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;convergence-analysis&quot;&gt;4. Convergence Analysis&lt;/h2&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;extensions-to-matrix-factorization&quot;&gt;5. Extensions to Matrix Factorization&lt;/h2&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;using-different-regularizers-for-alpha&quot;&gt;5.1 Using Different Regularizers for $\alpha$&lt;/h4&gt;

&lt;p&gt;Different priors for the coefficients $\alpha$ may lead to different regularizers $\Psi(\alpha)$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Positivity constraints on $\alpha$ that are added to the $l_1-regularization$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The Tikhonov regularization $\Psi(\alpha) = \frac{\lambda_1}{2}|\alpha|_2^2$, which doesn’t lead to sparse solutions&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The elastic net $\Psi(\alpha) = \lambda_1|\alpha|_1 + \frac{\lambda_2}{2}|\alpha|_2^2$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The group Lasso $\Psi(\alpha) = \sum_{i=1}^s|\alpha|_2$&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There is &lt;strong&gt;&lt;em&gt;no theoretical convergence results in exploiting non-convex regularizers&lt;/em&gt;&lt;/strong&gt; such as $l_0$ pseduo-norm and $l_p$ pseduo-norm with $p &amp;lt; 1$&lt;/p&gt;

&lt;h4 id=&quot;using-different-constraint-sets-for-d&quot;&gt;5.2 Using Different Constraint Sets for $D$&lt;/h4&gt;

&lt;p&gt;In dictionary learning, we use an $l_2$-regularization on $D$ by forcing its columns to have less than unit $l_2-norm$, and thus the dictionary update step can be solved efficiently using a block-coordinate descent approach&lt;/p&gt;

&lt;p&gt;We can use different convex constraint sets $C′$ as long as the constraints are a union of independent constraints on each column of $D$ and the orthogonal projections of the vectors $u_j$ onto $C′$ can be done efficiently&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The “non-negative” constraints&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;C = \{D \in R^{m * k}\quad s.t. \quad \forall j=1, ... ,k \quad \|d_j\|_2 \le 1 \quad and \quad d_j \ge 0\}&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;The “elastic-net” constraints&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;C = \{D \in R^{m * k}\quad s.t. \quad \forall j=1, ... ,k \quad \|d_j\|_2^2+\gamma\|d_j\|_1 \le 1\}&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Using the $l_1-norm$ only in such problems lead to trivial solutions when $k$ is large enough&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The “fused lasso” constraints&lt;/p&gt;

    &lt;p&gt;This kind of regularization has proven to be useful for &lt;strong&gt;&lt;em&gt;exploiting genomic data&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;C = \{D \in R^{m * k}\quad s.t. \quad \forall j=1, ... ,k \quad \|d_j\|_2^2 + \gamma_1\|d_j\|_1 + \gamma_2FL(d_j) \le 1\}&lt;/script&gt;

    &lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;FL(u) = \sum_{i=2}^m \|u[i]-u[i-1]\|&lt;/script&gt; which is the $l_1-norm$ of the consecutive differences of $u$&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The &lt;strong&gt;&lt;em&gt;orthogonal projection onto the “non negative” ball&lt;/em&gt;&lt;/strong&gt; is simple (additional thresholding)&lt;/p&gt;

&lt;p&gt;But &lt;strong&gt;&lt;em&gt;the projection onto the two other sets&lt;/em&gt;&lt;/strong&gt; is slightly more involved, however they can also be done efficently using some algorithms&lt;/p&gt;

&lt;h4 id=&quot;non-negative-matrix-factorization-nmf&quot;&gt;5.3 Non Negative Matrix Factorization (NMF)&lt;/h4&gt;

&lt;h4 id=&quot;sparse-principal-component-analysis-spca&quot;&gt;5.4 Sparse Principal Component Analysis (SPCA)&lt;/h4&gt;

&lt;h4 id=&quot;constrained-sparse-coding&quot;&gt;5.5 Constrained Sparse Coding&lt;/h4&gt;

&lt;h4 id=&quot;simultaneous-sparse-coding&quot;&gt;5.6 Simultaneous Sparse Coding&lt;/h4&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;experimental-validation&quot;&gt;6. Experimental Validation&lt;/h2&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>icbcbicc</name></author><summary>Online Learning for Matrix Factorization and Sparse Coding
Authors: Julien Mairal, Francis Bach, Jean Ponce, Guillermo Sapiro
PDF</summary></entry><entry><title>Online Detection of Unusual Events in Videos via Dynamic Sparse Coding</title><link href="http://icbcbicc.github.io/2016/09/17/Online-Detection-of-Unusual-Events-in-Videos-via-Dynamic-Sparse-Coding/" rel="alternate" type="text/html" title="Online Detection of Unusual Events in Videos via Dynamic Sparse Coding" /><published>2016-09-17T00:00:00+08:00</published><updated>2016-09-17T00:00:00+08:00</updated><id>http://icbcbicc.github.io/2016/09/17/Online Detection of Unusual Events in Videos via Dynamic Sparse Coding</id><content type="html" xml:base="http://icbcbicc.github.io/2016/09/17/Online-Detection-of-Unusual-Events-in-Videos-via-Dynamic-Sparse-Coding/">&lt;h1 id=&quot;online-detection-of-unusual-events-in-videos-via-dynamic-sparse-coding&quot;&gt;Online Detection of Unusual Events in Videos via Dynamic Sparse Coding&lt;/h1&gt;
&lt;p&gt;Authors: &lt;em&gt;Bin Zhou, Li Fei-Fei, Eric P. Xing&lt;/em&gt;
&lt;a href=&quot;http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5995524&quot;&gt;PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;####&lt;/p&gt;</content><author><name>icbcbicc</name></author><summary>Online Detection of Unusual Events in Videos via Dynamic Sparse Coding
Authors: Bin Zhou, Li Fei-Fei, Eric P. Xing
PDF</summary></entry><entry><title>Sparse Reconstruction Cost for Abnormal Event Detection</title><link href="http://icbcbicc.github.io/2016/09/17/Sparse-Reconstruction-Cost-for-Abnormal-Event-Detection/" rel="alternate" type="text/html" title="Sparse Reconstruction Cost for Abnormal Event Detection" /><published>2016-09-17T00:00:00+08:00</published><updated>2016-09-17T00:00:00+08:00</updated><id>http://icbcbicc.github.io/2016/09/17/Sparse Reconstruction Cost for Abnormal Event Detection</id><content type="html" xml:base="http://icbcbicc.github.io/2016/09/17/Sparse-Reconstruction-Cost-for-Abnormal-Event-Detection/">&lt;h1 id=&quot;sparse-reconstruction-cost-for-abnormal-event-detection&quot;&gt;Sparse Reconstruction Cost for Abnormal Event Detection&lt;/h1&gt;
&lt;p&gt;Authors: &lt;em&gt;Yang Cong, Junsong Yuan, Ji Liu&lt;/em&gt;&lt;br /&gt;
&lt;a href=&quot;http://www.cs.rochester.edu/~jliu/paper/Cong-Yuan-CVPR11.pdf&quot;&gt;PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;conventional-algorithms&quot;&gt;Conventional Algorithms&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;em&gt;Probability Model&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;Detect testing sample with lower probability as anormaly by fitting a probability model to the training data. However, the required number of training data increases exponentially with the feature dimension, and it’s unrealistic to collect enough data for density estimation in practice&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;sparse-reconstruction-cost-src&quot;&gt;Sparse Reconstruction Cost (SRC)&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;We propose SRC based on the weighted $l_1$ minimization.
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Normal event: generate sparse reconstruction coefficients with a &lt;strong&gt;small SRC&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Abnormal events: generate a dense representation with a &lt;strong&gt;large SRC&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;types-of-abnormal-events&quot;&gt;2 types of abnormal events:&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Local abnormal event (LAE)&lt;/p&gt;

    &lt;p&gt;The local behavior is different from its spatio temporal neighborhoods&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Global abnormal event (GAE)&lt;/p&gt;

    &lt;p&gt;The whole scene is abnormal, even though any individual lcoal behavior can be normal&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;New dictionary selection method&lt;/p&gt;

    &lt;p&gt;Reduce the size of the basis set $\phi$ for an efficient reconstruction&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>icbcbicc</name></author><summary>Sparse Reconstruction Cost for Abnormal Event Detection
Authors: Yang Cong, Junsong Yuan, Ji Liu
PDF</summary></entry><entry><title>Sparse and Redundant Modeling of Image Content Using an Image-Signature-Dictionary</title><link href="http://icbcbicc.github.io/2016/09/16/Sparse-and-Redundant-Modeling-of-Image-Content-Using-an-Image-Signature-Dictionary/" rel="alternate" type="text/html" title="Sparse and Redundant Modeling of Image Content Using an Image-Signature-Dictionary" /><published>2016-09-16T00:00:00+08:00</published><updated>2016-09-16T00:00:00+08:00</updated><id>http://icbcbicc.github.io/2016/09/16/Sparse and Redundant Modeling of Image Content Using an Image-Signature-Dictionary</id><content type="html" xml:base="http://icbcbicc.github.io/2016/09/16/Sparse-and-Redundant-Modeling-of-Image-Content-Using-an-Image-Signature-Dictionary/">&lt;h1 id=&quot;sparse-and-redundant-modeling-of-image-content-using-an-image-signature-dictionary&quot;&gt;Sparse and Redundant Modeling of Image Content Using an Image-Signature-Dictionary&lt;/h1&gt;
&lt;p&gt;Authors: &lt;em&gt;Michal Aharon and Michael Elad&lt;/em&gt;&lt;br /&gt;
&lt;a href=&quot;http://epubs.siam.org/doi/pdf/10.1137/07070156X&quot;&gt;PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;introduction-of-sparse-representation&quot;&gt;Introduction of Sparse Representation&lt;/h2&gt;

&lt;h4 id=&quot;background&quot;&gt;Background&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;In sparse and redundant modeling, a signal $y \in R^n$ is represented as a linear combination of some atoms taken from a dictionary $D \in R^{n*m}$ which contains $m$ atoms $d_i \in R^n$. A representation of the signal $y$ is then any vector $x \in R^n$ satisfying $y = Dx$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$m &amp;gt; n$: the representation is &lt;strong&gt;&lt;em&gt;redundant&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The solutions to $y = Dx$ are infinite and we prefer the sparest one, i.e, &lt;strong&gt;&lt;em&gt;the one with the smallest ${||x||}_0$&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The task of &lt;strong&gt;&lt;em&gt;computing a representation&lt;/em&gt;&lt;/strong&gt; of a signal can be formly described by&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;min_x{\|x\|}_0 \qquad s.t. \qquad y=Dx&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;However, the &lt;strong&gt;&lt;em&gt;constrait above is often relaxed&lt;/em&gt;&lt;/strong&gt; and replaced by ${||y-Dx||}_2 \le \epsilon$. This allows for additive noise and model deviations&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;problem&quot;&gt;Problem&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Solving this problem was proved to be an &lt;strong&gt;NP-hard&lt;/strong&gt; problem&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Two approximation techniques :&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Matching-pursuit (MP) methods that ﬁnd the solution one entry at a time in a greedy way&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Basis-pursuit (BP) algorithm that replaces the $L_0$ norm by the $L_1$ norm&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Two types of dictionary&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Prespeciﬁed dictionaries&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Dictionaries obtained by learning procedure&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;this-paper&quot;&gt;This paper&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;The &lt;strong&gt;image-signature-dictionary&lt;/strong&gt; (ISD), is an 2D image in which each patch can serve as a representing atom&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;A near shift-invariant property is obtained, due to the &lt;strong&gt;overlap between atoms&lt;/strong&gt; extracted from the ISD in nearby locations&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;By &lt;strong&gt;taking patches of varying sizes&lt;/strong&gt;, near scale-invariance is potentially obtained and exploited&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;the-structure-of-isd&quot;&gt;The Structure of ISD&lt;/h2&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;y = \sum_{k=1}^{\sqrt{m}}\sum_{l=1}^{\sqrt{m}}x_{[k,l]}C_{[k,l]}d_s = Dx&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;$D_s \in R^{\sqrt{m}*\sqrt{m}} : $ signature dictionary&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$y’ \in R^{\sqrt{n}*\sqrt{n}} : $ imasge patch and its single column form $y \in R^n$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$d_s \in R^m : $  a vector obtained by a column lexicographic ordering of the ISD&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$C_{[k,l]} : $ the linear operator that extract a patch of size $\sqrt{n}*\sqrt{n}$ from the $D_s$ in location $[k,l]$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$C_{[k,l]}d_s : $ the extracted patch as a column vector&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$x$ is the concatenation of the $m$ coeﬃcients in the array $x_{[k,l]}$&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;isd-training&quot;&gt;ISD Training&lt;/h2&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;energy-function&quot;&gt;Energy Function&lt;/h4&gt;

&lt;p&gt;We assume that each patch is represented by a &lt;strong&gt;ﬁxed number of atoms&lt;/strong&gt;, L. The &lt;strong&gt;energy function&lt;/strong&gt; that the ISD is expected to minimize :&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{d_s} = Arg min_{d_s} \sum_{i=1}^N \epsilon_i^2(d_s)&lt;/script&gt;

&lt;p&gt;s.t.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\epsilon_i^2(d_s) = min_x {\|y_i-\sum_{k=1}^{\sqrt{m}}\sum_{l=1}^{\sqrt{m}}x_{[k,l]}C_{[k,l]}d_s\|}_2^2&lt;/script&gt;

&lt;p&gt;s.t.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;{\|x\|}_0 \le L,\qquad 1 \le i \le N&lt;/script&gt;

&lt;h4 id=&quot;two-stages-in-training&quot;&gt;Two stages in training&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;The sparse coding stage: find $\hat{x_i}$&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;Assuming that $d_s$ is known and ﬁxed, we can solve the &lt;strong&gt;inner optimization problem&lt;/strong&gt; and ﬁnd the sparsest representation $\hat{x_i}$ for each example $y_i$&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{x_i} = Argmin_x {\|y_i-\sum_{k=1}^{\sqrt{m}}\sum_{l=1}^{\sqrt{m}}x_{[k,l]}C_{[k,l]}d_s\|}_2^2 \qquad s.t. \qquad \|x_o\| \le L&lt;/script&gt;

    &lt;p&gt;This problem can be solved by any &lt;strong&gt;pursuit algorithm&lt;/strong&gt;, such as a greedy method——&lt;strong&gt;the orthogonal matching pursuit&lt;/strong&gt; (OMP)&lt;/p&gt;

    &lt;p&gt;The OMP selects at each stage an atom from the dictionary that best resembles the residual. After each such selection, the signal is back-projected onto the set of chosen atoms, and the new residual signal is calculated &lt;strong&gt;&lt;em&gt;(Don’t understand)&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Dictionary update stage: $\hat{d_s}$&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;Assuming that the sparse representation vectors $\hat{x_i}$ have been computed, we seek the best ISD $d_s$ to minimize:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;E(d_s) = \sum_{i=1}^N {\|y_i-\sum_{k=1}^{\sqrt{m}}\sum_{l=1}^{\sqrt{m}}x_{[k,l]}^iC_{[k,l]}d_s\|}_2^2&lt;/script&gt;

    &lt;p&gt;The &lt;strong&gt;gradient of the error expression&lt;/strong&gt;:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\partial E(d_s)}{\partial d_s} = Rd_s - p&lt;/script&gt;

    &lt;p&gt;where&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;R = \sum_{i=1}^N {\lgroup \sum_{k=1}^{\sqrt{m}}\sum_{l=1}^{\sqrt{m}}x_{[k,l]}^iC_{[k,l]} \rgroup}^T * {\lgroup \sum_{k=1}^{\sqrt{m}}\sum_{l=1}^{\sqrt{m}}x_{[k,l]}^iC_{[k,l]} \rgroup} \in R^{m*m}&lt;/script&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;p = \sum_{i=1}^N {\lgroup \sum_{k=1}^{\sqrt{m}}\sum_{l=1}^{\sqrt{m}}x_{[k,l]}^iC_{[k,l]} \rgroup}^T*y_i \in R^m&lt;/script&gt;

    &lt;p&gt;Thus, the &lt;strong&gt;optimal ISD&lt;/strong&gt; is obtained simply by:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{d_s} = R^{-1}p&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Stochastic gradient appoach (SG)&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;The algorithm above updates the $x_i$ for all examples {y_i}_{i=1}^N and then updates the ISD&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Another way is to update the ISD after the computation of each $x_i$ (SG):&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{d_s^{new}} = \hat{d_s^{lod}} - \mu \frac{\partial E(d_s^{lod})}{\partial d_s^{lod}} = \hat{d_s^{lod}} - \mu {\lgroup \sum_{k=1}^{\sqrt{m}}\sum_{l=1}^{\sqrt{m}}x_{[k,l]}^iC_{[k,l]} \rgroup}^T {\lgroup \sum_{k=1}^{\sqrt{m}}\sum_{l=1}^{\sqrt{m}}x_{[k,l]}^iC_{[k,l]}\hat{d_s^{old}}-y_i \rgroup}&lt;/script&gt;

    &lt;p&gt;The step-size parameter $\mu$ is typically set as $\mu = \frac{\mu_0}{Iteration}$&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;treatment-of-the-mean&quot;&gt;Treatment of the mean&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Remove the mean in training and testing data&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Redefine the $C_{[k,l]}$ to also remove the mean of the extrated patch&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>icbcbicc</name></author><summary>Sparse and Redundant Modeling of Image Content Using an Image-Signature-Dictionary
Authors: Michal Aharon and Michael Elad
PDF</summary></entry><entry><title>Abnormal Event Detection at 150 FPS in MATLAB</title><link href="http://icbcbicc.github.io/2016/09/04/Abnormal-Event-Detection-at-150-FPS-in-MATLAB/" rel="alternate" type="text/html" title="Abnormal Event Detection at 150 FPS in MATLAB" /><published>2016-09-04T00:00:00+08:00</published><updated>2016-09-04T00:00:00+08:00</updated><id>http://icbcbicc.github.io/2016/09/04/Abnormal Event Detection at 150 FPS in MATLAB</id><content type="html" xml:base="http://icbcbicc.github.io/2016/09/04/Abnormal-Event-Detection-at-150-FPS-in-MATLAB/">&lt;h1 id=&quot;abnormal-event-detection-at-150-fps-in-matlab&quot;&gt;Abnormal Event Detection at 150 FPS in MATLAB&lt;/h1&gt;

&lt;p&gt;Authors: &lt;em&gt;Cewu Lu, Jianping Shi, Jiaya Jia&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Lu_Abnormal_Event_Detection_2013_ICCV_paper.pdf&quot;&gt;PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;h4 id=&quot;difficulties-in-detecting-abnormal-events-based-on-surveillance-videos&quot;&gt;Difficulties in detecting abnormal events based on surveillance videos&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Hard to list all possible negative samples&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;traditional-method&quot;&gt;Traditional method&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Normal patterns are learned from training&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;And then the patterns are used to detect events deviated from this representation&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;other-methods&quot;&gt;Other methods&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Trajectories extracted from object-of-interest are used as normal patterns&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Learn normal low-level video feature distributions(exponential, multivariate Gaussian mixture, clustering)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Graph model normal event representations which use co-occurrence patterns&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;sparsity-based model(not fast enough for realtime processing due to the inherently intensive computation to build sparse representation)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;sparsity-based-abnormality-detection&quot;&gt;Sparsity Based Abnormality Detection&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;em&gt;Sparsity:  A general constraint to model normal event patterns as a linear combination of a set of basis atoms&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;em&gt;Computationally expensive&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;min\|x-D\beta\|^2_2 \qquad s.t. \qquad \|\beta\|_0 \le s&lt;/script&gt;

    &lt;p&gt;$\beta$ : parse coefficients&lt;/p&gt;

    &lt;p&gt;$|x-D\beta|^2_2 $ :data fitting term&lt;/p&gt;

    &lt;p&gt;$|\beta|_0$ : sparsity regulization term&lt;/p&gt;

    &lt;p&gt;$s$ : parameter to control sparsity&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;&lt;em&gt;&lt;font color=&quot;#9932CC&quot;&gt;abnormal pattern&lt;/font&gt;&lt;/em&gt;&lt;/strong&gt;: large error result from $|x-D\beta|^2_2$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;em&gt;&lt;font color=&quot;#9932CC&quot;&gt;Efficiency problem&lt;/font&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;&lt;strong&gt;Adopting $min|x-D\beta|^2_2$ is time-consuming :&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;ﬁnd the suitable basis vectors&lt;/strong&gt; (with scale $s$) from the dictionary (with scale $q$) to represent testing data $x$&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Search space is large &lt;strong&gt;( $(^q_s)$ different combinations )&lt;/strong&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;em&gt;&lt;font color=&quot;#9932CC&quot;&gt;Our contribution&lt;/font&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Instead of coding sparsity by ﬁnding an $s$ basis combination from $D$ in $min|x-D\beta|^2_2$, we code it directly &lt;strong&gt;as a set of possible combinations of basis vectors&lt;/strong&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;We only need to ﬁnd the most suitable combination by evaluating &lt;strong&gt;the small-scale least square error&lt;/strong&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;/img/3.JPG&quot; alt=&quot;Our testing architecture&quot; /&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Freely selecting $s$ basis vectors from a total of $q$ vectors, the reconstructed structure could deviate from input due to the &lt;strong&gt;large freedom&lt;/strong&gt;. However, in our method, &lt;strong&gt;&lt;font color=&quot;#9932CC&quot;&gt;each combination ﬁnds its corresponding input data&lt;/font&gt;&lt;/strong&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;It reaches 140∼150 FPS using a desktop with 3.4GHz CPU and 8G memory in MATLAB 2012.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;methods&quot;&gt;Methods&lt;/h2&gt;

&lt;h4 id=&quot;learning-combinations-on-training-data&quot;&gt;Learning Combinations on Training Data&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;Preprocess&lt;/em&gt;&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Resize each frame into different scales as “&lt;a href=&quot;http://101.110.118.63/www3.ntu.edu.sg/home/jsyuan/index_files/papers/Cong-Yuan-CVPR11.pdf&quot;&gt;Sparse Reconstruction Cost for Abnormal Event Detection&lt;/a&gt;”&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Uniformly partition each layer to a set of non-overlapping patches. All patches have the same size&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Corresponding regions in 5 continuous frames are stacked together to form a spatial-temporal cube.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;img src=&quot;/img/4.JPG&quot; alt=&quot;Resize&quot; /&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;This pyramid involves &lt;strong&gt;local information&lt;/strong&gt; in ﬁne-scale layers and more &lt;strong&gt;global structures&lt;/strong&gt; in small-resolution ones.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;With the spatial-temporal cubes, we compute &lt;strong&gt;3D gradient features&lt;/strong&gt; on each of them following “&lt;a href=&quot;https://www.cs.drexel.edu/~kon/publication/LKratz_CVPR09.pdf&quot;&gt;Anomaly Detection in Extremely Crowded Scenes Using Spatio-Temporal Motion Pattern Models&lt;/a&gt;”&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Features are processed separately according to their spatial coordinates. &lt;strong&gt;Only features at the same spatial location in the video frames are used together&lt;/strong&gt; for training and testing.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;em&gt;Learning Combinations on Training Data&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;3D gradient features&lt;/strong&gt; in all frames gathered temporally for training are denoted as &lt;script type=&quot;math/tex&quot;&gt;X=\{x_1, x_2, ..., x_n\} \in R^{p*n}&lt;/script&gt;. Each $x_i$ has $p$ features and there are $n$ $x_i$ in the $X$&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Our goal is to &lt;strong&gt;find a sparse basis combination set&lt;/strong&gt; &lt;script type=&quot;math/tex&quot;&gt;S=\{S_1, S_2, ..., S_K\}&lt;/script&gt; with each $S_i \in R^{p*s}$. Each $S_i$ combines $s$ dictionary basis vectors and each basis vector has $p$ features which correspond to the features in $x_i$. Each $S_i$ belongs to a closed, convex and bounded set, which ensures column-wise unit norm to &lt;strong&gt;prevent over-ﬁtting&lt;/strong&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;Reconstruction Error&lt;/strong&gt;
 	&lt;script type=&quot;math/tex&quot;&gt;t=min_{s,\gamma,\beta}\sum_{j=1}^n\sum_{i=1}^K\gamma_j^i\|x_j-S_i\beta_j^i\|_2^2 \quad s.t. \sum_{i=1}^K\gamma_j^i=1,\gamma_j^i=\{0,1\}&lt;/script&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Each $\gamma_j^i$ indicates whether or not the $i^{th}%$ combination $S_i$ is chosen for data $x_j$ and &lt;strong&gt;only one combination $S_i$ is selected for each $x_j$&lt;/strong&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;$K$ must be small enough&lt;/strong&gt; because a very large $K$ could possibly make the reconstruction error $t$ always close to zero&lt;strong&gt;(Don’t understand)&lt;/strong&gt;, even for abnormal events. However, we want the errors to be larger for abnormal events&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;em&gt;Optimization for Training&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;Problem : Reducing $K$ could increase reconstruction errors $t$&lt;/strong&gt;. And it is not optimal to ﬁx $K$ as well, as content may vary among videos&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;Solution :&lt;/strong&gt;  A maximum representation strategy. It &lt;strong&gt;automatically ﬁnds $K$ while not wildly increasing the reconstruction error $t$&lt;/strong&gt;. In fact, error $t$ for each training feature is upper bounded in our method&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;Updated function&lt;/strong&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;t_j=\sum_{i=1}^K\gamma_j^i \{ \|x_j-S_i\beta_j^i \|_2^2 -\lambda \} \le 0,\quad s.t. \sum_{i=1}^K\gamma_j^i=1,\gamma_j^i=\{0,1\}&lt;/script&gt;

    &lt;ul&gt;
      &lt;li&gt;$\lambda :$  We obtain a set of combinations with a small $K$ by setting a reconstruction error upper bound $\lambda$ uniformly for each $S_i$. If $t_j$ is smaller than $\lambda$, the coding result is with good quality&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;em&gt;Algorithm&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;In each pass, we update only one combination&lt;/strong&gt;, making it represent as many training data as possible&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;This process can &lt;strong&gt;quickly ﬁnd the dominating combinations encoding important and most common features&lt;/strong&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Remaining training cube features that cannot be well represented by this combination are &lt;strong&gt;sent to the next round to gather residual maximum commonness&lt;/strong&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;This process &lt;strong&gt;ends until all training data are computed and bounded&lt;/strong&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;The size of combination $K$ reﬂects how informative the training data are&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;In each pass, we &lt;strong&gt;solve the equation above by interatively update ${S_s^i,\beta}$ and $\lambda$&lt;/strong&gt;&lt;/p&gt;
        &lt;ol&gt;
          &lt;li&gt;&lt;strong&gt;Update ${S_s^i,\beta}$&lt;/strong&gt; :&lt;/li&gt;
        &lt;/ol&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;L(\beta,S_i)=\sum_{j \in \Omega_c}\gamma_j^i \{ \|x_j-S_i\beta_j^i \|_2^2 \}&lt;/script&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;\beta_j^i=(S_i^TS_i)^{-1}S_i^Tx_j&lt;/script&gt;

        &lt;p&gt;(Optimize $\beta$ while ﬁxing $S_i$ for all $\gamma_j^i \neq 0$)&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;S_i=\prod[S_i-\delta_t\bigtriangledown_{S_i}L(\beta,S_i)]&lt;/script&gt;

        &lt;p&gt;( Using &lt;strong&gt;block-coordinate descent&lt;/strong&gt;( &lt;a href=&quot;http://www.jmlr.org/papers/volume11/mairal10a/mairal10a.pdf&quot;&gt;Online learning for matrix factorization and sparse coding&lt;/a&gt; and set $\delta = 1E-4$)&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;strong&gt;Update $\gamma$&lt;/strong&gt; :&lt;/li&gt;
        &lt;/ol&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\gamma_j^i = \left\{
  \begin{aligned}
  1 \quad &amp; if \quad \|x_j-S_i\beta_j^i \|_2^2 &lt; \lambda ; \\
  0 \quad &amp; otherwise ;\\
  \end{aligned}
  \right . %]]&gt;&lt;/script&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;/img/5.JPG&quot; alt=&quot;Algorithm 1&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;&lt;strong&gt;The algorithm is controlled by $\lambda$, Reducing it could lead to a larger $K$&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;em&gt;Testing&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;With the learned sparse combinations $S = {S_1, …, S_K}$, in the testing phase with new data $x$, we checki f there exists a combination in $S$ ﬁtting the $\lambda$. It can be quickly achieved by checking the least square error for each $S_i$&lt;/li&gt;
    &lt;/ul&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;min_{\beta^i}\|x_j-S_i\beta_j^i \|_2^2 \quad \forall i= 1, ..., K&lt;/script&gt;

    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;optimal solution :&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{\beta^i}=(S_i^TS_i)^{-1}S_i^Tx&lt;/script&gt;

    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Reconstruction error in $S_i$ :&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\|x_j-S_i\beta_j^i \|_2^2 = \|((S_i^TS_i)^{-1}S_i^T-I_p)x\|_2^2=\|R_ix\|_2^2&lt;/script&gt;

    &lt;p&gt;&lt;img src=&quot;/img/6.JPG&quot; alt=&quot;Algorithm 2&quot; /&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;It is noted that the ﬁrst a few dominating combinations represent the largest number of normal event features.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Easy to parallel to achieve $O(1)$ complexity&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Average combination checking ratio $= \frac{The\  number\ of\ combinations\ checked}{The\ total\ number\ K}$&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;Relation to Subspace Clustering&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;experiments&quot;&gt;Experiments&lt;/h2&gt;

&lt;h4 id=&quot;system-settings&quot;&gt;System Settings&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Resize each frame to 3 scales&lt;/strong&gt;: $20*20, 30*40, 120*160$ pixels respectively&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Uniformly &lt;strong&gt;partition each layer to a set of non-overlapping 10×10 patches&lt;/strong&gt; (totaly 208 sub-regions for each frame $\frac{20*30+30*40+120*160}{10*10}=208$ )&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/img/7.JPG&quot; alt=&quot;Patches in 3 scales, each region corresponds to a K&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Corresponding sub-regions in 5 continuous frames are stacked together to form a spatial temporal cube with resolution $10*10*5$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Compute 3D gradient features&lt;/strong&gt; on each cube and concatenate them into a 1500-dimension feature vector&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Reduce the feature vector to 100 dimensions via &lt;strong&gt;PCA&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Normalize&lt;/strong&gt; the reduced feature vector to make it mean 0 and variance 1&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;For each frame, we compute an &lt;strong&gt;abnormal indicator $V$&lt;/strong&gt; by summing the number of cubes in each scale with weights&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;V=\sum_{i=1}^n 2^{n-i}v_i&lt;/script&gt;

    &lt;p&gt;$v_i$ : the number of abnormal cubes in scale $i$, the top scale is with index $1$ while the bottom one is with $n$.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;verification-of-sparse-combinations&quot;&gt;Verification of Sparse Combinations&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Each video contains 208 regions and each region correspond to a cube and there are 6000-12000 features in each sube&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The features are used to &lt;strong&gt;verify the combination model&lt;/strong&gt;. The number of combinations for each region is $K$&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/img/8.JPG&quot; alt=&quot;The distribution of K in 31200 regions from 150 videos&quot; /&gt;
  The mean of $K$ is 9.75 and variance is 10.62, indicating 10 combinations are generally enough in our model&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;说人话&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;假设有一个学习好的$D\in R^{p \times q}$, 稀疏系数$\alpha_i$的0范数小于等于$s$&lt;/p&gt;

    &lt;p&gt;也就是每个样本$x_i$最多能用$s$个字典基来表达。因为要稀疏，显然有$s « q$&lt;/p&gt;

    &lt;p&gt;对于每个$x_i$，测试时都要从$q$个字典基中找出$s$个来表示，要求使得损失函数最小。&lt;/p&gt;

    &lt;p&gt;&lt;strong&gt;&lt;em&gt;因此这种测试方式很花时间（每次都在求解一个优化问题）&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;这篇文章主要解决了效率问题，提出了新的测试方式（训练$D$的方式也随之改变）：&lt;/p&gt;

    &lt;p&gt;预先训练好$K$个稀疏表达$S_1 … S_K$，每个表达$S_i$都由$D$中的$s$个字典基组成&lt;/p&gt;

    &lt;p&gt;测试时，将$x_i$与每个$S_i$计算得到损失函数，选择损失最小的$S_i$即可&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;重点在于得到$K$个$S_i$：&lt;/p&gt;

    &lt;p&gt;设置一个损失函数上限$\lambda$，低于这个上限就认为编码质量好&lt;/p&gt;

    &lt;p&gt;每个周期更新一个$S_i$，使其遍历在之前的周期还未被很好表达的$x_i$（也就是说，不论用什么已获得的$S_i$，该$x_i$的损失函数都超过$\lambda$）。&lt;/p&gt;

    &lt;p&gt;对于每个周期未被很好表达的$x_i$，都留到下一个周期通过新的$S_i$来表达。如此循环直到所有$x_i$都可以被很好的表达。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在每次循环得到新的$S_i$的过程中：&lt;/p&gt;

    &lt;p&gt;目标函数为：
  &lt;script type=&quot;math/tex&quot;&gt;min_{S_i,\gamma,\beta}\sum_{i=1}^K\gamma_j^i ( \|x_j-S_i\beta_j^i \|_2^2 -\lambda ),\quad s.t. \sum_{i=1}^K\gamma_j^i=1,\gamma_j^i=\{0,1\}&lt;/script&gt;&lt;/p&gt;

    &lt;p&gt;&lt;strong&gt;&lt;em&gt;分 2 步解决这个问题&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;更新$S_s^i,\beta$ :&lt;/p&gt;

        &lt;p&gt;(更新 $\beta$ 时固定 $S_i$ 并且所有 $\gamma_j^i \neq 0$)&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;
            &lt;script type=&quot;math/tex; mode=display&quot;&gt;\beta_j^i=(S_i^TS_i)^{-1}S_i^Tx_j&lt;/script&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;script type=&quot;math/tex; mode=display&quot;&gt;S_i=\prod[S_i-\delta_t\bigtriangledown_{S_i}L(\beta,S_i)]&lt;/script&gt;

            &lt;script type=&quot;math/tex; mode=display&quot;&gt;\delta = 1E-4&lt;/script&gt;
          &lt;/li&gt;
        &lt;/ol&gt;

        &lt;p&gt;详情请见&lt;a href=&quot;http://127.0.0.1:4001/2016/09/21/Online-Learning-for-Matrix-Factorization-and-Sparse-Coding/&quot;&gt;Online Learning for Matrix Factorization and Sparse Coding&lt;/a&gt;中的算法1和算法2&lt;/p&gt;

        &lt;p&gt;&lt;img src=&quot;/img/5.JPG&quot; alt=&quot;Algorithm 1&quot; /&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;更新&lt;strong&gt;$\gamma$&lt;/strong&gt; :&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\gamma_j^i = \left\{
  \begin{aligned}
  1 \quad &amp; if \quad \|x_j-S_i\beta_j^i \|_2^2 &lt; \lambda ; \\
  0 \quad &amp; otherwise ;\\
  \end{aligned}
  \right . %]]&gt;&lt;/script&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;测试&lt;/p&gt;

    &lt;p&gt;对于目标函数：
  &lt;script type=&quot;math/tex&quot;&gt;min_{\beta^i}\|x_j-S_i\beta_j^i \|_2^2 \quad \forall i= 1, ..., K&lt;/script&gt;&lt;/p&gt;

    &lt;p&gt;最优解为:
  &lt;script type=&quot;math/tex&quot;&gt;\hat{\beta^i}=(S_i^TS_i)^{-1}S_i^Tx&lt;/script&gt;&lt;/p&gt;

    &lt;p&gt;损失函数可化为：
  &lt;script type=&quot;math/tex&quot;&gt;\|x_j-S_i\beta_j^i \|_2^2 = \|((S_i^TS_i)^{-1}S_i^T-I_p)x\|_2^2=\|R_ix\|_2^2&lt;/script&gt;&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/img/6.JPG&quot; alt=&quot;Algorithm 2&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>icbcbicc</name></author><summary>Abnormal Event Detection at 150 FPS in MATLAB</summary></entry></feed>
