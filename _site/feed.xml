<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom"><generator uri="http://jekyllrb.com" version="3.1.6">Jekyll</generator><link href="http://icbcbicc.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="http://icbcbicc.github.io/" rel="alternate" type="text/html" /><updated>2016-10-04T15:51:32+08:00</updated><id>http://icbcbicc.github.io/</id><title>Jam&#39;s Blog</title><subtitle>Write your site description here. It will be used as your sites meta description as well!</subtitle><entry><title>Online Detection of Abnormal Events Using Incremental Coding Length</title><link href="http://icbcbicc.github.io/2016/10/04/Online-Detection-of-Abnormal-Events-Using-Incremental-Coding-Length/" rel="alternate" type="text/html" title="Online Detection of Abnormal Events Using Incremental Coding Length" /><published>2016-10-04T00:00:00+08:00</published><updated>2016-10-04T00:00:00+08:00</updated><id>http://icbcbicc.github.io/2016/10/04/Online Detection of Abnormal Events Using Incremental Coding Length</id><content type="html" xml:base="http://icbcbicc.github.io/2016/10/04/Online-Detection-of-Abnormal-Events-Using-Incremental-Coding-Length/">&lt;h1 id=&quot;online-detection-of-abnormal-events-using-incremental-coding-length&quot;&gt;Online Detection of Abnormal Events Using Incremental Coding Length&lt;/h1&gt;

&lt;p&gt;Authors: &lt;em&gt;Jatanta K.Dutta, Bonny Banerjee&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://pdfs.semanticscholar.org/83f6/d84389dcdc25a4a1462044d7b1cbc2e75eac.pdf&quot;&gt;PDF&lt;/a&gt;&lt;/p&gt;</content><author><name>icbcbicc</name></author><summary>Online Detection of Abnormal Events Using Incremental Coding Length</summary></entry><entry><title>The Negative —— Part 2</title><link href="http://icbcbicc.github.io/2016/10/02/The-Negative-Part-2/" rel="alternate" type="text/html" title="The Negative —— Part 2" /><published>2016-10-02T00:00:00+08:00</published><updated>2016-10-02T00:00:00+08:00</updated><id>http://icbcbicc.github.io/2016/10/02/The Negative Part 2</id><content type="html" xml:base="http://icbcbicc.github.io/2016/10/02/The-Negative-Part-2/">&lt;h2 id=&quot;section&quot;&gt;4. 区域选置&lt;/h2&gt;

&lt;p&gt;由于区域选置这一概念是基于其他重要概念之上的，因此我们先介绍一些基本概念。&lt;/p&gt;</content><author><name>icbcbicc</name></author><summary>4. 区域选置</summary></entry><entry><title>The Negative —— Part 1</title><link href="http://icbcbicc.github.io/2016/10/01/The-Negative-Part-1/" rel="alternate" type="text/html" title="The Negative —— Part 1" /><published>2016-10-01T00:00:00+08:00</published><updated>2016-10-01T00:00:00+08:00</updated><id>http://icbcbicc.github.io/2016/10/01/The Negative Part 1</id><content type="html" xml:base="http://icbcbicc.github.io/2016/10/01/The-Negative-Part-1/">&lt;h2 id=&quot;section&quot;&gt;1. 简介&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;最终目标:&lt;/strong&gt; 视觉化&lt;/p&gt;

&lt;p&gt;（摄影的）的工艺与技术尽管很重要，但它们永远是屈从于摄影师的表达观念的。换句话说，它们是必须的而不是主要的。&lt;/p&gt;

&lt;p&gt;有一点值得注意的是：摄影的表达，或者说摄影的创意与现实是没有直接的关系的。我们不会将观察到的事物的内在价值直接复制到照片中。但我们会模仿这些价值，或者将他们呈现在它相关的感情中。很多人认为我的照片是“写实”的。实际上，他们所谓的“现实”只是他们认为自己眼中图像是准确的，这种“现实”是是绝对偏离了真正的现实的。之所以观看者会认为我的作品是写实的，是因为作品的视觉效果很合理和可信。如果将我的作品与其中所表现的事物拿出来直接对比，就会显现出巨大的视觉差异。&lt;/p&gt;

&lt;p&gt;要实现令人满意的视觉化，关键在于在底片上体现合适的信息。&lt;/p&gt;

&lt;p&gt;实现视觉化的第一步是 &lt;strong&gt;图像管理&lt;/strong&gt;，这在此系列的第一本书（&lt;em&gt;The Camera&lt;/em&gt;）中有详细阐述，它涉及到你的观念和相机的调整。在这本书中我们将要讨论 &lt;strong&gt;图像值&lt;/strong&gt; 的控制。它是通过曝光、冲洗和其他一些因素决定的。当然，因为我们的最终目标是得到相片（正像），所以我们会根据最终的正像来讨论负片的控制。第三本书（&lt;em&gt;The Print&lt;/em&gt;）将详细地阐述得到正像和放大的过程。&lt;/p&gt;

&lt;p&gt;尽管我们分不同阶段阐述了视觉化和相关技术，但在实际操作中，我们应该一开始就把整个过程当作以一个整体来考虑。摄影是一个复杂、流动的介质，它的很多因素都不是按顺序执行的，就像杂耍艺人在抛球时要保持几个球同时在空中一样。&lt;/p&gt;

&lt;p&gt;自从1940年以来，分区系统就已经应用在摄影中。它被人们支持过也被反对过。它也有很多种不同的解释方式，但不是所有的解释都是正确的，因为这些解释与感光的原理相矛盾。现在我用的分区系统的值的范围是0到10（原文使用罗马数字，为方便书写，在此使用阿拉伯数字替代），0代表纯黑，10代表纯白。实际上，我们一般使用1和9作为真实亮度的极限，这个范围包含了所有的纹理与元素。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;2. 了解光线&lt;/h2&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;2.1 人类的视觉与摄影&lt;/h3&gt;

&lt;p&gt;制作一副高质量的黑白影像，关键在于学会预想彩色场景转化为黑白之后的效果。因此，研究人眼感知能力与摄影捕捉图像的能力之间所存在的差异很重要。人眼所能感知的影调范围比胶片所能记录的范围大得多。人的视觉系统能够接受1000000：1的动态范围，这让人眼可以在深夜或者阳光直射之下看清纸上的字。这意味着我们能够看到20档的动态范围。然而在胶片上，只能捕捉1000：1的动态范围，也就是10档的影调范围。区域系统理论的一个主要目的就是调整胶片的动态范围。&lt;/p&gt;

&lt;p&gt;相比摄影，人眼还具有“色彩自适应”的优点——比如我们看到阴影中的一座白色的房子，虽然它呈现出灰色，但我们还是会把他看成“白色”。然而胶片就没有这种功能，它只能保持动态范围不变。运用区域系统理论进行拍摄与显影，就能使得照片中的景象和看到的一样。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;section-3&quot;&gt;2.2 光线的性质&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;反射光&lt;/strong&gt;&lt;br /&gt;
室外场景中，大部分光线都是反射光。被摄对象的材质（光滑程度、颜色深浅）和光线的入射角度都会影响胶片对它的记录。比如白色的墙壁能够将光线反射到其他物体上从而提亮阴影，减少反差。反之，一排影调较深的树木则会吸收环境光，保持阴影不被体谅，从而增加反差。&lt;/p&gt;

    &lt;p&gt;光线都有色彩倾向，它会对反射光的强度造成一定的影响。比如，在日出或者日落时光线偏红，因此绿色物体的反射光就会减弱。同样，阴影处的光线就会偏蓝，并且减少对黄色或者红色物体的反射率。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;直射光&lt;/strong&gt;&lt;br /&gt;
当某一光源的位置相聚拍摄对象较远时，或者被摄对象相对较小时，所产生的是直射光（硬光）。这种光线会产生较强的反差（明亮的高光与边缘清晰的阴影）&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;漫射光&lt;/strong&gt;&lt;br /&gt;
漫射光所产生的阴影相比直射光更加柔和甚至消失。柔光箱可以制造漫射光源，但如果它离被摄物体较远，就达不到效果。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;要注意的是，光线的性质与光线的强度没有直接的关系。&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Sweet Light&lt;/strong&gt;&lt;br /&gt;
这种光线只存在于日出前的半个小时到一个小时，和日落后的半个小时到一个小时。其时间长短取决于天气的情况。尽管这是一种漫射光，但他的反差范围很大。天空中最明亮的区域位于地平线附近，光线缺乏方向性，会着照亮很多阴影。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-4&quot;&gt;3. 分区尺标&lt;/h2&gt;

&lt;p&gt;分区尺标是区域系统的标志性元素，他也被称做灰阶或区域尺。它是由一系列连续变化的11个影调组成的，分别标记为0区到10区（纯黑到纯白）。分区尺标可以分为3个人部分：暗部区域（0，1，2）、细节区域、高光区域。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/11.JPG&quot; alt=&quot;灰阶&quot; /&gt;&lt;/p&gt;

&lt;p&gt;以下是几个对影像特征的描述：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;影纹&lt;/strong&gt;：能感受到影调的变化，但是没有图像信息&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;微弱的细节&lt;/strong&gt;：包含信息较少&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;肌理&lt;/strong&gt;：具有一定锐度的重复的影调变化&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;清晰的细节&lt;/strong&gt;：丰富的信息&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-5&quot;&gt;3.1 暗部区域（0-1 区）&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;0区（纯黑）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;对于负片来说，就是没有可用密度。然而并没有一个硬性的规定，要求0区必须占多少比例。黑色为照片的动态范围建立了基础。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;1区（近似于纯黑）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这一区域的影调与0区很难区分，在没有0区的对比下，很容易将其误认为0区。这一点是胶片特性曲线直线段的起点，从这个区开始，每增加一档曝光，密度也会增加一个区。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/12.JPG&quot; alt=&quot;胶片与相纸的特性曲线&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;2区（有影纹的暗部）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;2区是除了表现影调之外还能提供图像信息的最暗的区，它大约有5%的反射率。因为2区位于胶片特征曲线的直线段，所以它是第一个始终可以进行“选置”的区。我们可以用反射式测光表读出数据，在此基础上降低3档曝光来获得2区的曝光参数。&lt;/p&gt;

&lt;h4 id=&quot;section-6&quot;&gt;3.2 细节区域（3-7 区）&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;3区（暗部细节）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;它是我们能看到清晰细节的区域中影调最深的一个。3区确定了影像的基调。3区是确认正确曝光的基本标准。因为如果在曝光时没有在底片上记录下暗部细节，那么无论怎样显影都不会呈现任何影像。因此，我们通常将3区作为暗部测光法的测量区域，也可以作为平均测光法的暗部测光区域。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;4区（影调较深的中灰区域）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;4区是暗部过度到亮部的起始区。它与6区这两个过渡区对于照片的反差起到了决定性的作用。如果过渡区变小，反差就会较大。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;5区（中灰区域）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;它位于整个影调区域的正中间，并处在倒易律范围（2-8区）。5区能反射照射在该区域上的约18%的光线&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;6区（较浅的中灰区）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;它是中间影调向高光区过渡的起始区域。6区是高调影像的基础。当拍摄白人肖像时，可以对其手掌测光获得曝光数值&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;7区（表现高光区域中的细节）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;7区是细节区域中最亮的一个区域，有将近72%的反射率。如果图像大部分都落在这一区域，图像就会很柔美、明亮与轻盈。它被作为平均测光法的亮部测光区。在暗室印放过程中，7区也是检验影响密度是否合适的目标区。因为7区以上的区域的密度变化会受到胶片曲线肩部的影像，形成更宽的影调范围。&lt;/p&gt;

&lt;h4 id=&quot;section-7&quot;&gt;3.3 高光区域（8-10区）&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;8区（有影纹的高光区域）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;8区是最亮的仍然包含有影像信息的区域，8区以上的区域之间已经不再是线性关系。但在测光表读数的基础上增加3档曝光则会精确地落在8区。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;9区（接近纯白）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;只有将10区与9区放在一起才能区分两者。9区位于曲线地肩部终点，也就是说如果测量一张照片的9区，会达到最低密度&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;10区（纯白）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;纸基的白度决定了10区的效果。但在后期处理照片时，很容易污染纯白的相纸。比如安全灯会在相纸上形成轻微的灰雾，过度冲洗会减少氧化钡图层。化学污渍，不完全定影与纸基干燥后影调变深，都会造成照片高光区域的动态范围损失。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;center&gt;============ 接 Part 2 =============&lt;/center&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>icbcbicc</name></author><summary>1. 简介</summary></entry><entry><title>Online Learning for Matrix Factorization and Sparse Coding</title><link href="http://icbcbicc.github.io/2016/09/21/Online-Learning-for-Matrix-Factorization-and-Sparse-Coding/" rel="alternate" type="text/html" title="Online Learning for Matrix Factorization and Sparse Coding" /><published>2016-09-21T00:00:00+08:00</published><updated>2016-09-21T00:00:00+08:00</updated><id>http://icbcbicc.github.io/2016/09/21/Online Learning for Matrix Factorization and Sparse Coding</id><content type="html" xml:base="http://icbcbicc.github.io/2016/09/21/Online-Learning-for-Matrix-Factorization-and-Sparse-Coding/">&lt;h1 id=&quot;online-learning-for-matrix-factorization-and-sparse-coding&quot;&gt;Online Learning for Matrix Factorization and Sparse Coding&lt;/h1&gt;
&lt;p&gt;Authors: &lt;em&gt;Julien Mairal, Francis Bach, Jean Ponce, Guillermo Sapiro&lt;/em&gt;&lt;br /&gt;
&lt;a href=&quot;http://www.jmlr.org/papers/volume11/mairal10a/mairal10a.pdf&quot;&gt;PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/b5dfacb7-b178-4002-823e-fc5dcfd2d641.png&quot; alt=&quot;mindmap&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;1. Introduction&lt;/h2&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Linear decompositon of a matrix using learned dictionary instead of pre-defined one&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Usage:&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;low-level: image denoising, texture synthesis, audio processing&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;high-level: image classification&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Differences between maxtrix factorization and PCA:&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;It doesn’t impose that the basis vector to be orthogonal&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Allowing more flexibility to adapt the representation to the data&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Variants matrix factorization problem:&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Non-negtive matrix factorization&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Sparse PCA&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;problem-statement&quot;&gt;2. Problem Statement&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Optimize the &lt;strong&gt;&lt;em&gt;empirical cost function:&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;f_n(D) = \frac{1}{n}\sum_{i=1}^n l (x_i,D)&lt;/script&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;$D\in R^{m * k}$ :dictionary&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;$m &amp;lt; &amp;lt; n$: feature nums less than sample nums&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;$k &amp;lt; &amp;lt; n$: atom nums of dictoinary less than sample nums&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;$k &amp;gt; m$: &lt;strong&gt;&lt;em&gt;Overcomplete dictionary&lt;/em&gt;&lt;/strong&gt;: atoms more than feature nums&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$l_1$ sparse coding problem (&lt;strong&gt;&lt;em&gt;basis pursuit&lt;/em&gt;&lt;/strong&gt;):&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;l_1(x,D) = min\frac{1}{2}{\|x-D\alpha\|}_2^2+\lambda\|\alpha\|_1 \quad s.t. \quad \alpha \in R^k&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Disadvantage:&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;There is no direct analytic link between the value of $\lambda$ and the corresponding effective sparsity $|\alpha|_0$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Solution:&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;To prevent $D$ from having arbitrarily large values (which would lead to arbitrarily small values of $\alpha$), it is common to &lt;strong&gt;&lt;em&gt;constrain its columns $d_1, . . . ,d_k$ to have an $l_2-norm$&lt;/em&gt;&lt;/strong&gt; less than or equal to 1&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;C = \{D \in R^{m * k}\quad s.t. \quad \forall j=1, ... ,k \quad d_j^Td_j \le 1\}&lt;/script&gt;

    &lt;p&gt;It’s a joint optimization problem with respet to $D$ and $\alpha=[\alpha_1, …, \alpha_k] \in R^{k * n}$, which is &lt;strong&gt;&lt;em&gt;not jointly convex&lt;/em&gt;&lt;/strong&gt; but &lt;strong&gt;&lt;em&gt;convex with respect to each of the two variables&lt;/em&gt;&lt;/strong&gt; $D$ and $\alpha$ when the other one is fixed&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Optimization method:&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;&lt;em&gt;Alternate between the two variables&lt;/em&gt;&lt;/strong&gt;, minimizing over one while keeping the other one fixed&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Since the computation of $\alpha$ dominates the cost of each iteration in this &lt;strong&gt;&lt;em&gt;block-coordinate descent&lt;/em&gt;&lt;/strong&gt; approach, a &lt;strong&gt;&lt;em&gt;second-order optimization&lt;/em&gt;&lt;/strong&gt; technique can be used to accurately estimate $D$ at each step when $\alpha$ is fixed&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;em&gt;Stochastic gradient&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;Its rate of convergence is very poor in conventional optimization terms, may in fact in certain settings &lt;strong&gt;&lt;em&gt;to be faster in reaching a solution with low expected cost than second-order batch&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Dictionary learning:&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;The classical &lt;strong&gt;&lt;em&gt;projected first-order projected stochastic gradient descent&lt;/em&gt;&lt;/strong&gt; consists of a sequence of updates of $D$&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;D_t = \prod [{D_{t-1}-\delta_t \nabla_C l(x_t,D_{t-1})}]&lt;/script&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;$\nabla_C: \quad$ Orthogonal projector onto $C$&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;$x_t: \quad$ i.i.d samples obtained by cycling on a randomly permuted training set&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;$\delta_t: \quad$ learning rate(good results are obtained using  $\delta_t = \frac{a}{t+b}$ where $a$ and $b$ are chosen depended on the training data)&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;online-dictionary-learning&quot;&gt;3. Online Dictionary Learning&lt;/h2&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;algorithm-outline&quot;&gt;3.1 Algorithm Outline&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Assuming that the training set is composed of &lt;strong&gt;&lt;em&gt;i.i.d. samples&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;script type=&quot;math/tex; mode=display&quot;&gt;f_t(D) = \frac{1}{t}\sum_{i=1}^t l (x_i,D)&lt;/script&gt;

    &lt;p&gt;and&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{f_t}(D) = \frac{1}{t}\sum_{i=1}^t(\frac{1}{2}\|x_i-D\alpha_i\|_2^2+\lambda\|\alpha_i\|_1)&lt;/script&gt;

    &lt;p&gt;&lt;strong&gt;&lt;em&gt;converge almost surely to the same limit&lt;/em&gt;&lt;/strong&gt;, and thus that $\hat{f_t}$ acts as a surrogate for $f_t$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Since $\hat{f_t}$ is close to $\hat{f_{t-1}}$ for large values of $t$, so are $D_t$ and $D_{t−1}$, use $D_{t−1}$ as &lt;strong&gt;&lt;em&gt;warm restart&lt;/em&gt;&lt;/strong&gt; for computing $D_t$ can acceerate this algorithm&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;sparse-coding&quot;&gt;3.2 Sparse Coding&lt;/h4&gt;

&lt;p&gt;This is a &lt;strong&gt;&lt;em&gt;$l_1$ regularized linear least-squares problem :&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;l_1(x,D) = min\frac{1}{2}{\|x-D\alpha\|}_2^2+\lambda\|\alpha\|_1 \quad s.t. \quad \alpha \in R^k&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Traditional method&lt;/strong&gt; (&lt;strong&gt;&lt;em&gt;Coordinate descent with soft thresholding&lt;/em&gt;&lt;/strong&gt;)&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;It is efficient when the columns of the dictionary are &lt;strong&gt;&lt;em&gt;low correlated&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;Problem:&lt;/strong&gt; The columns of learned dictionaries are in general &lt;strong&gt;&lt;em&gt;highly correlated&lt;/em&gt;&lt;/strong&gt;, which make this method rather slow&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;New method&lt;/strong&gt; (&lt;strong&gt;&lt;em&gt;LARS-Lasso algorithm&lt;/em&gt;&lt;/strong&gt;)&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;With an efficient Cholesky-based implementation, it is at least as fast as the one above&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;It provides the solution with a &lt;strong&gt;&lt;em&gt;higher accuracy&lt;/em&gt;&lt;/strong&gt; and being more robust since it does not require an arbitrary stopping criterion&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/img/9.JPG&quot; alt=&quot;Sparse Coding&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;dictionary-update&quot;&gt;3.3 Dictionary Update&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/img/10.JPG&quot; alt=&quot;Dictionary update&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;The procedure does not require to store all the vectors $x_i$ and $\alpha_i$, but only $A_t$ and $B_t$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Sequentially updates each column of $D$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Orthogonal projection on to $C$(the constraint set)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;In practice, the matrix $A_t$ are often &lt;strong&gt;&lt;em&gt;concentrated on the diagonal&lt;/em&gt;&lt;/strong&gt;, which makes the block-coordinate descent more efficient&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;optimizing-the-algorithm&quot;&gt;3.4 Optimizing the Algorithm&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;em&gt;3.4.1&lt;/em&gt;&lt;/strong&gt; Handling fixed-size data sets&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;&lt;em&gt;Problem:&lt;/em&gt;&lt;/strong&gt; When the data sets are predefined and have finite size, the same data points may be examined several times&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;&lt;em&gt;Solution:&lt;/em&gt;&lt;/strong&gt; When the training set is small enough, it is possible to further speed up convergence:&lt;/p&gt;

        &lt;p&gt;If the sample $x$ has been drawn from the data sets twice in the iteration $t_0$ and $t$, we will replace $\alpha_{t_0}$ by $\alpha_t$ in $A_t$ and $B_t$, that is&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;A_t = A_{t-1} + \alpha_t\alpha_t^T - \alpha_{t_0}\alpha_{t_0}^T&lt;/script&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;B_t = B_{t-1} + x_t\alpha_t^T - x_t\alpha_{t_0}^T&lt;/script&gt;

        &lt;p&gt;In this setting, we need to store $\alpha_i$ in every iteration and it’s &lt;strong&gt;&lt;em&gt;impractical&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

        &lt;p&gt;However, we can sovle this by removing the information from $A_t$ and $B_t$ that is older than two epochs(cycles through the data)&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;em&gt;3.4.2&lt;/em&gt;&lt;/strong&gt; Scaling te past data&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;&lt;em&gt;Problem:&lt;/em&gt;&lt;/strong&gt; At each iteration, the “new” information $\alpha_t$ that is added to $A_t$ and $B_t$ has the same weight as the “old” one&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;&lt;em&gt;Solution:&lt;/em&gt;&lt;/strong&gt; Rescaling the “old” information so that newer coefficients $\alpha_t$ have more weight, which is classical in online learning&lt;/p&gt;

        &lt;p&gt;We propose to replace lines 5 and 6 of Algorithm 1 by:&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;A_t = \beta_t A_{t-1} + \alpha_t\alpha_t^T&lt;/script&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;B_t = \beta_t B_{t-1} + x_t\alpha_t^T&lt;/script&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;\beta_t = (1-\frac{1}{t})^\rho&lt;/script&gt;

        &lt;p&gt;In this circumstance, we propose&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;D_t = argmin_{D \in C}\frac{1}{\sum_{j=1}^t(j/t)} \sum_{i=1}^t(\frac{i}{t})^\rho(\frac{1}{2}\|x_i-D\alpha_i\|_2^2+\lambda\|\alpha_i\|_1)&lt;/script&gt;

        &lt;p&gt;=&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;argmin_{D \in C}\frac{1}{\sum_{j=1}^t(j/t)}(\frac{1}{2}Tr(D^TDA_t)-Tr(D^TB_t))&lt;/script&gt;

        &lt;p&gt;When $\rho = 0$, we obtain the original version of the algorithm&lt;/p&gt;

        &lt;p&gt;&lt;strong&gt;&lt;em&gt;In practice, this parameter $\rho$ is only useful for large data sets $(n \ge 100000)$&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;em&gt;3.4.3&lt;/em&gt;&lt;/strong&gt; Mini-batch extension&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;The complexity of computing $\eta$ vectors $\alpha_i$ is not linear in $\eta$&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;A &lt;strong&gt;&lt;em&gt;Cholesky-based implementation of LARS-Lasso&lt;/em&gt;&lt;/strong&gt; for decomposing one signal has a complexity of $O(kms+ks^2)$, where $s$ is the number of nonzero coefficient&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;When decomposing $\eta$ signals, it is possible to &lt;strong&gt;&lt;em&gt;pre-compute the Gram matrix $D^T_tD_t$&lt;/em&gt;&lt;/strong&gt; and the total complexity becomes $O(k^2m+\eta(km+ks^2))$, which is much cheaper than $\eta$ times the previous complexity when $\eta$ is large enough and $s$ is small&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;We propose to replace lines 5 and 6 of Algorithm 1 by:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;A_t = A_{t-1} + \frac{1}{\eta}\sum_{i=1}^\eta \alpha_{t,i} \alpha_{t,i}^T&lt;/script&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;B_t = B_{t-1} + \frac{1}{\eta}\sum_{i=1}^\eta x_{t,i}\alpha_{t,i}^T&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;em&gt;3.4.4&lt;/em&gt;&lt;/strong&gt; Slowing down the first iterations&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;&lt;em&gt;Problem:&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;The first iterations of our algorithm may update the parameters with large steps, immediately leading to large deviations from the initial dictionary&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;&lt;em&gt;solution:&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;Use gradient steps of the form $\frac{a}{b+t}$&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;$b$ will slow down the first few steps&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;An initialization of the form $A_0 = t_0I$ and $B_0 = t_0 D_0$ with $t_0 \ge 0$ will also slow down the first steps&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;em&gt;3.4.5&lt;/em&gt;&lt;/strong&gt; Puring the dictionary from unused atoms&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;&lt;em&gt;Problem:&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;Some of the dictionary atoms are never (or very seldom) used, which typically happens with a very bad initialization&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;&lt;em&gt;solution:&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;In general cases, replacing these atoms during the optimization by randomly chosen elements of the training set&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;For more difficult and highly regularized cases, choosing a continuation strategy consisting of starting from an easier, less regularized problem, and gradually increasing $\lambda$&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;link-with-second-order-stochastic-gradient-descent&quot;&gt;3.5 Link with Second-order Stochastic Gradient Descent&lt;/h4&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;convergence-analysis&quot;&gt;4. Convergence Analysis&lt;/h2&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;extensions-to-matrix-factorization&quot;&gt;5. Extensions to Matrix Factorization&lt;/h2&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;using-different-regularizers-for-alpha&quot;&gt;5.1 Using Different Regularizers for $\alpha$&lt;/h4&gt;

&lt;p&gt;Different priors for the coefficients $\alpha$ may lead to different regularizers $\Psi(\alpha)$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Positivity constraints on $\alpha$ that are added to the $l_1-regularization$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The Tikhonov regularization $\Psi(\alpha) = \frac{\lambda_1}{2}|\alpha|_2^2$, which doesn’t lead to sparse solutions&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The elastic net $\Psi(\alpha) = \lambda_1|\alpha|_1 + \frac{\lambda_2}{2}|\alpha|_2^2$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The group Lasso $\Psi(\alpha) = \sum_{i=1}^s|\alpha|_2$&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There is &lt;strong&gt;&lt;em&gt;no theoretical convergence results in exploiting non-convex regularizers&lt;/em&gt;&lt;/strong&gt; such as $l_0$ pseduo-norm and $l_p$ pseduo-norm with $p &amp;lt; 1$&lt;/p&gt;

&lt;h4 id=&quot;using-different-constraint-sets-for-d&quot;&gt;5.2 Using Different Constraint Sets for $D$&lt;/h4&gt;

&lt;p&gt;In dictionary learning, we use an $l_2$-regularization on $D$ by forcing its columns to have less than unit $l_2-norm$, and thus the dictionary update step can be solved efficiently using a block-coordinate descent approach&lt;/p&gt;

&lt;p&gt;We can use different convex constraint sets $C′$ as long as the constraints are a union of independent constraints on each column of $D$ and the orthogonal projections of the vectors $u_j$ onto $C′$ can be done efficiently&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The “non-negative” constraints&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;C = \{D \in R^{m * k}\quad s.t. \quad \forall j=1, ... ,k \quad \|d_j\|_2 \le 1 \quad and \quad d_j \ge 0\}&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;The “elastic-net” constraints&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;C = \{D \in R^{m * k}\quad s.t. \quad \forall j=1, ... ,k \quad \|d_j\|_2^2+\gamma\|d_j\|_1 \le 1\}&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Using the $l_1-norm$ only in such problems lead to trivial solutions when $k$ is large enough&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The “fused lasso” constraints&lt;/p&gt;

    &lt;p&gt;This kind of regularization has proven to be useful for &lt;strong&gt;&lt;em&gt;exploiting genomic data&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;C = \{D \in R^{m * k}\quad s.t. \quad \forall j=1, ... ,k \quad \|d_j\|_2^2 + \gamma_1\|d_j\|_1 + \gamma_2FL(d_j) \le 1\}&lt;/script&gt;

    &lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;FL(u) = \sum_{i=2}^m \|u[i]-u[i-1]\|&lt;/script&gt; which is the $l_1-norm$ of the consecutive differences of $u$&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The &lt;strong&gt;&lt;em&gt;orthogonal projection onto the “non negative” ball&lt;/em&gt;&lt;/strong&gt; is simple (additional thresholding)&lt;/p&gt;

&lt;p&gt;But &lt;strong&gt;&lt;em&gt;the projection onto the two other sets&lt;/em&gt;&lt;/strong&gt; is slightly more involved, however they can also be done efficently using some algorithms&lt;/p&gt;

&lt;h4 id=&quot;non-negative-matrix-factorization-nmf&quot;&gt;5.3 Non Negative Matrix Factorization (NMF)&lt;/h4&gt;

&lt;h4 id=&quot;sparse-principal-component-analysis-spca&quot;&gt;5.4 Sparse Principal Component Analysis (SPCA)&lt;/h4&gt;

&lt;h4 id=&quot;constrained-sparse-coding&quot;&gt;5.5 Constrained Sparse Coding&lt;/h4&gt;

&lt;h4 id=&quot;simultaneous-sparse-coding&quot;&gt;5.6 Simultaneous Sparse Coding&lt;/h4&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;experimental-validation&quot;&gt;6. Experimental Validation&lt;/h2&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>icbcbicc</name></author><summary>Online Learning for Matrix Factorization and Sparse Coding
Authors: Julien Mairal, Francis Bach, Jean Ponce, Guillermo Sapiro
PDF</summary></entry><entry><title>Online Detection of Unusual Events in Videos via Dynamic Sparse Coding</title><link href="http://icbcbicc.github.io/2016/09/17/Online-Detection-of-Unusual-Events-in-Videos-via-Dynamic-Sparse-Coding/" rel="alternate" type="text/html" title="Online Detection of Unusual Events in Videos via Dynamic Sparse Coding" /><published>2016-09-17T00:00:00+08:00</published><updated>2016-09-17T00:00:00+08:00</updated><id>http://icbcbicc.github.io/2016/09/17/Online Detection of Unusual Events in Videos via Dynamic Sparse Coding</id><content type="html" xml:base="http://icbcbicc.github.io/2016/09/17/Online-Detection-of-Unusual-Events-in-Videos-via-Dynamic-Sparse-Coding/">&lt;h1 id=&quot;online-detection-of-unusual-events-in-videos-via-dynamic-sparse-coding&quot;&gt;Online Detection of Unusual Events in Videos via Dynamic Sparse Coding&lt;/h1&gt;
&lt;p&gt;Authors: &lt;em&gt;Bin Zhou, Li Fei-Fei, Eric P. Xing&lt;/em&gt;
&lt;a href=&quot;http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5995524&quot;&gt;PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;####&lt;/p&gt;</content><author><name>icbcbicc</name></author><summary>Online Detection of Unusual Events in Videos via Dynamic Sparse Coding
Authors: Bin Zhou, Li Fei-Fei, Eric P. Xing
PDF</summary></entry><entry><title>Sparse Reconstruction Cost for Abnormal Event Detection</title><link href="http://icbcbicc.github.io/2016/09/17/Sparse-Reconstruction-Cost-for-Abnormal-Event-Detection/" rel="alternate" type="text/html" title="Sparse Reconstruction Cost for Abnormal Event Detection" /><published>2016-09-17T00:00:00+08:00</published><updated>2016-09-17T00:00:00+08:00</updated><id>http://icbcbicc.github.io/2016/09/17/Sparse Reconstruction Cost for Abnormal Event Detection</id><content type="html" xml:base="http://icbcbicc.github.io/2016/09/17/Sparse-Reconstruction-Cost-for-Abnormal-Event-Detection/">&lt;h1 id=&quot;sparse-reconstruction-cost-for-abnormal-event-detection&quot;&gt;Sparse Reconstruction Cost for Abnormal Event Detection&lt;/h1&gt;
&lt;p&gt;Authors: &lt;em&gt;Yang Cong, Junsong Yuan, Ji Liu&lt;/em&gt;&lt;br /&gt;
&lt;a href=&quot;http://www.cs.rochester.edu/~jliu/paper/Cong-Yuan-CVPR11.pdf&quot;&gt;PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;conventional-algorithms&quot;&gt;Conventional Algorithms&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;em&gt;Probability Model&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;Detect testing sample with lower probability as anormaly by fitting a probability model to the training data. However, the required number of training data increases exponentially with the feature dimension, and it’s unrealistic to collect enough data for density estimation in practice&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;sparse-reconstruction-cost-src&quot;&gt;Sparse Reconstruction Cost (SRC)&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;We propose SRC based on the weighted $l_1$ minimization.
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Normal event: generate sparse reconstruction coefficients with a &lt;strong&gt;small SRC&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Abnormal events: generate a dense representation with a &lt;strong&gt;large SRC&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;types-of-abnormal-events&quot;&gt;2 types of abnormal events:&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Local abnormal event (LAE)&lt;/p&gt;

    &lt;p&gt;The local behavior is different from its spatio temporal neighborhoods&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Global abnormal event (GAE)&lt;/p&gt;

    &lt;p&gt;The whole scene is abnormal, even though any individual lcoal behavior can be normal&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;New dictionary selection method&lt;/p&gt;

    &lt;p&gt;Reduce the size of the basis set $\phi$ for an efficient reconstruction&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>icbcbicc</name></author><summary>Sparse Reconstruction Cost for Abnormal Event Detection
Authors: Yang Cong, Junsong Yuan, Ji Liu
PDF</summary></entry><entry><title>Sparse and Redundant Modeling of Image Content Using an Image-Signature-Dictionary</title><link href="http://icbcbicc.github.io/2016/09/16/Sparse-and-Redundant-Modeling-of-Image-Content-Using-an-Image-Signature-Dictionary/" rel="alternate" type="text/html" title="Sparse and Redundant Modeling of Image Content Using an Image-Signature-Dictionary" /><published>2016-09-16T00:00:00+08:00</published><updated>2016-09-16T00:00:00+08:00</updated><id>http://icbcbicc.github.io/2016/09/16/Sparse and Redundant Modeling of Image Content Using an Image-Signature-Dictionary</id><content type="html" xml:base="http://icbcbicc.github.io/2016/09/16/Sparse-and-Redundant-Modeling-of-Image-Content-Using-an-Image-Signature-Dictionary/">&lt;h1 id=&quot;sparse-and-redundant-modeling-of-image-content-using-an-image-signature-dictionary&quot;&gt;Sparse and Redundant Modeling of Image Content Using an Image-Signature-Dictionary&lt;/h1&gt;
&lt;p&gt;Authors: &lt;em&gt;Michal Aharon and Michael Elad&lt;/em&gt;&lt;br /&gt;
&lt;a href=&quot;http://epubs.siam.org/doi/pdf/10.1137/07070156X&quot;&gt;PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;introduction-of-sparse-representation&quot;&gt;Introduction of Sparse Representation&lt;/h2&gt;

&lt;h4 id=&quot;background&quot;&gt;Background&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;In sparse and redundant modeling, a signal $y \in R^n$ is represented as a linear combination of some atoms taken from a dictionary $D \in R^{n*m}$ which contains $m$ atoms $d_i \in R^n$. A representation of the signal $y$ is then any vector $x \in R^n$ satisfying $y = Dx$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$m &amp;gt; n$: the representation is &lt;strong&gt;&lt;em&gt;redundant&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The solutions to $y = Dx$ are infinite and we prefer the sparest one, i.e, &lt;strong&gt;&lt;em&gt;the one with the smallest ${||x||}_0$&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The task of &lt;strong&gt;&lt;em&gt;computing a representation&lt;/em&gt;&lt;/strong&gt; of a signal can be formly described by&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;min_x{\|x\|}_0 \qquad s.t. \qquad y=Dx&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;However, the &lt;strong&gt;&lt;em&gt;constrait above is often relaxed&lt;/em&gt;&lt;/strong&gt; and replaced by ${||y-Dx||}_2 \le \epsilon$. This allows for additive noise and model deviations&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;problem&quot;&gt;Problem&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Solving this problem was proved to be an &lt;strong&gt;NP-hard&lt;/strong&gt; problem&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Two approximation techniques :&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Matching-pursuit (MP) methods that ﬁnd the solution one entry at a time in a greedy way&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Basis-pursuit (BP) algorithm that replaces the $L_0$ norm by the $L_1$ norm&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Two types of dictionary&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Prespeciﬁed dictionaries&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Dictionaries obtained by learning procedure&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;this-paper&quot;&gt;This paper&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;The &lt;strong&gt;image-signature-dictionary&lt;/strong&gt; (ISD), is an 2D image in which each patch can serve as a representing atom&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;A near shift-invariant property is obtained, due to the &lt;strong&gt;overlap between atoms&lt;/strong&gt; extracted from the ISD in nearby locations&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;By &lt;strong&gt;taking patches of varying sizes&lt;/strong&gt;, near scale-invariance is potentially obtained and exploited&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;the-structure-of-isd&quot;&gt;The Structure of ISD&lt;/h2&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;y = \sum_{k=1}^{\sqrt{m}}\sum_{l=1}^{\sqrt{m}}x_{[k,l]}C_{[k,l]}d_s = Dx&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;$D_s \in R^{\sqrt{m}*\sqrt{m}} : $ signature dictionary&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$y’ \in R^{\sqrt{n}*\sqrt{n}} : $ imasge patch and its single column form $y \in R^n$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$d_s \in R^m : $  a vector obtained by a column lexicographic ordering of the ISD&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$C_{[k,l]} : $ the linear operator that extract a patch of size $\sqrt{n}*\sqrt{n}$ from the $D_s$ in location $[k,l]$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$C_{[k,l]}d_s : $ the extracted patch as a column vector&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$x$ is the concatenation of the $m$ coeﬃcients in the array $x_{[k,l]}$&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;isd-training&quot;&gt;ISD Training&lt;/h2&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;energy-function&quot;&gt;Energy Function&lt;/h4&gt;

&lt;p&gt;We assume that each patch is represented by a &lt;strong&gt;ﬁxed number of atoms&lt;/strong&gt;, L. The &lt;strong&gt;energy function&lt;/strong&gt; that the ISD is expected to minimize :&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{d_s} = Arg min_{d_s} \sum_{i=1}^N \epsilon_i^2(d_s)&lt;/script&gt;

&lt;p&gt;s.t.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\epsilon_i^2(d_s) = min_x {\|y_i-\sum_{k=1}^{\sqrt{m}}\sum_{l=1}^{\sqrt{m}}x_{[k,l]}C_{[k,l]}d_s\|}_2^2&lt;/script&gt;

&lt;p&gt;s.t.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;{\|x\|}_0 \le L,\qquad 1 \le i \le N&lt;/script&gt;

&lt;h4 id=&quot;two-stages-in-training&quot;&gt;Two stages in training&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;The sparse coding stage: find $\hat{x_i}$&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;Assuming that $d_s$ is known and ﬁxed, we can solve the &lt;strong&gt;inner optimization problem&lt;/strong&gt; and ﬁnd the sparsest representation $\hat{x_i}$ for each example $y_i$&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{x_i} = Argmin_x {\|y_i-\sum_{k=1}^{\sqrt{m}}\sum_{l=1}^{\sqrt{m}}x_{[k,l]}C_{[k,l]}d_s\|}_2^2 \qquad s.t. \qquad \|x_o\| \le L&lt;/script&gt;

    &lt;p&gt;This problem can be solved by any &lt;strong&gt;pursuit algorithm&lt;/strong&gt;, such as a greedy method——&lt;strong&gt;the orthogonal matching pursuit&lt;/strong&gt; (OMP)&lt;/p&gt;

    &lt;p&gt;The OMP selects at each stage an atom from the dictionary that best resembles the residual. After each such selection, the signal is back-projected onto the set of chosen atoms, and the new residual signal is calculated &lt;strong&gt;&lt;em&gt;(Don’t understand)&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Dictionary update stage: $\hat{d_s}$&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;Assuming that the sparse representation vectors $\hat{x_i}$ have been computed, we seek the best ISD $d_s$ to minimize:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;E(d_s) = \sum_{i=1}^N {\|y_i-\sum_{k=1}^{\sqrt{m}}\sum_{l=1}^{\sqrt{m}}x_{[k,l]}^iC_{[k,l]}d_s\|}_2^2&lt;/script&gt;

    &lt;p&gt;The &lt;strong&gt;gradient of the error expression&lt;/strong&gt;:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\partial E(d_s)}{\partial d_s} = Rd_s - p&lt;/script&gt;

    &lt;p&gt;where&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;R = \sum_{i=1}^N {\lgroup \sum_{k=1}^{\sqrt{m}}\sum_{l=1}^{\sqrt{m}}x_{[k,l]}^iC_{[k,l]} \rgroup}^T * {\lgroup \sum_{k=1}^{\sqrt{m}}\sum_{l=1}^{\sqrt{m}}x_{[k,l]}^iC_{[k,l]} \rgroup} \in R^{m*m}&lt;/script&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;p = \sum_{i=1}^N {\lgroup \sum_{k=1}^{\sqrt{m}}\sum_{l=1}^{\sqrt{m}}x_{[k,l]}^iC_{[k,l]} \rgroup}^T*y_i \in R^m&lt;/script&gt;

    &lt;p&gt;Thus, the &lt;strong&gt;optimal ISD&lt;/strong&gt; is obtained simply by:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{d_s} = R^{-1}p&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Stochastic gradient appoach (SG)&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;The algorithm above updates the $x_i$ for all examples {y_i}_{i=1}^N and then updates the ISD&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Another way is to update the ISD after the computation of each $x_i$ (SG):&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{d_s^{new}} = \hat{d_s^{lod}} - \mu \frac{\partial E(d_s^{lod})}{\partial d_s^{lod}} = \hat{d_s^{lod}} - \mu {\lgroup \sum_{k=1}^{\sqrt{m}}\sum_{l=1}^{\sqrt{m}}x_{[k,l]}^iC_{[k,l]} \rgroup}^T {\lgroup \sum_{k=1}^{\sqrt{m}}\sum_{l=1}^{\sqrt{m}}x_{[k,l]}^iC_{[k,l]}\hat{d_s^{old}}-y_i \rgroup}&lt;/script&gt;

    &lt;p&gt;The step-size parameter $\mu$ is typically set as $\mu = \frac{\mu_0}{Iteration}$&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;treatment-of-the-mean&quot;&gt;Treatment of the mean&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Remove the mean in training and testing data&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Redefine the $C_{[k,l]}$ to also remove the mean of the extrated patch&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>icbcbicc</name></author><summary>Sparse and Redundant Modeling of Image Content Using an Image-Signature-Dictionary
Authors: Michal Aharon and Michael Elad
PDF</summary></entry><entry><title>Abnormal Event Detection at 150 FPS in MATLAB</title><link href="http://icbcbicc.github.io/2016/09/04/Abnormal-Event-Detection-at-150-FPS-in-MATLAB/" rel="alternate" type="text/html" title="Abnormal Event Detection at 150 FPS in MATLAB" /><published>2016-09-04T00:00:00+08:00</published><updated>2016-09-04T00:00:00+08:00</updated><id>http://icbcbicc.github.io/2016/09/04/Abnormal Event Detection at 150 FPS in MATLAB</id><content type="html" xml:base="http://icbcbicc.github.io/2016/09/04/Abnormal-Event-Detection-at-150-FPS-in-MATLAB/">&lt;h1 id=&quot;abnormal-event-detection-at-150-fps-in-matlab&quot;&gt;Abnormal Event Detection at 150 FPS in MATLAB&lt;/h1&gt;

&lt;p&gt;Authors: &lt;em&gt;Cewu Lu, Jianping Shi, Jiaya Jia&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Lu_Abnormal_Event_Detection_2013_ICCV_paper.pdf&quot;&gt;PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;h4 id=&quot;difficulties-in-detecting-abnormal-events-based-on-surveillance-videos&quot;&gt;Difficulties in detecting abnormal events based on surveillance videos&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Hard to list all possible negative samples&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;traditional-method&quot;&gt;Traditional method&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Normal patterns are learned from training&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;And then the patterns are used to detect events deviated from this representation&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;other-methods&quot;&gt;Other methods&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Trajectories extracted from object-of-interest are used as normal patterns&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Learn normal low-level video feature distributions(exponential, multivariate Gaussian mixture, clustering)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Graph model normal event representations which use co-occurrence patterns&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;sparsity-based model(not fast enough for realtime processing due to the inherently intensive computation to build sparse representation)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;sparsity-based-abnormality-detection&quot;&gt;Sparsity Based Abnormality Detection&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;em&gt;Sparsity:  A general constraint to model normal event patterns as a linear combination of a set of basis atoms&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;em&gt;Computationally expensive&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;min\|x-D\beta\|^2_2 \qquad s.t. \qquad \|\beta\|_0 \le s&lt;/script&gt;

    &lt;p&gt;$\beta$ : parse coefficients&lt;/p&gt;

    &lt;p&gt;$|x-D\beta|^2_2 $ :data fitting term&lt;/p&gt;

    &lt;p&gt;$|\beta|_0$ : sparsity regulization term&lt;/p&gt;

    &lt;p&gt;$s$ : parameter to control sparsity&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;&lt;em&gt;&lt;font color=&quot;#9932CC&quot;&gt;abnormal pattern&lt;/font&gt;&lt;/em&gt;&lt;/strong&gt;: large error result from $|x-D\beta|^2_2$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;em&gt;&lt;font color=&quot;#9932CC&quot;&gt;Efficiency problem&lt;/font&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;&lt;strong&gt;Adopting $min|x-D\beta|^2_2$ is time-consuming :&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;ﬁnd the suitable basis vectors&lt;/strong&gt; (with scale $s$) from the dictionary (with scale $q$) to represent testing data $x$&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Search space is large &lt;strong&gt;( $(^q_s)$ different combinations )&lt;/strong&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;em&gt;&lt;font color=&quot;#9932CC&quot;&gt;Our contribution&lt;/font&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Instead of coding sparsity by ﬁnding an $s$ basis combination from $D$ in $min|x-D\beta|^2_2$, we code it directly &lt;strong&gt;as a set of possible combinations of basis vectors&lt;/strong&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;We only need to ﬁnd the most suitable combination by evaluating &lt;strong&gt;the small-scale least square error&lt;/strong&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;/img/3.JPG&quot; alt=&quot;Our testing architecture&quot; /&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Freely selecting $s$ basis vectors from a total of $q$ vectors, the reconstructed structure could deviate from input due to the &lt;strong&gt;large freedom&lt;/strong&gt;. However, in our method, &lt;strong&gt;&lt;font color=&quot;#9932CC&quot;&gt;each combination ﬁnds its corresponding input data&lt;/font&gt;&lt;/strong&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;It reaches 140∼150 FPS using a desktop with 3.4GHz CPU and 8G memory in MATLAB 2012.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;methods&quot;&gt;Methods&lt;/h2&gt;

&lt;h4 id=&quot;learning-combinations-on-training-data&quot;&gt;Learning Combinations on Training Data&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;Preprocess&lt;/em&gt;&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Resize each frame into different scales as “&lt;a href=&quot;http://101.110.118.63/www3.ntu.edu.sg/home/jsyuan/index_files/papers/Cong-Yuan-CVPR11.pdf&quot;&gt;Sparse Reconstruction Cost for Abnormal Event Detection&lt;/a&gt;”&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Uniformly partition each layer to a set of non-overlapping patches. All patches have the same size&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Corresponding regions in 5 continuous frames are stacked together to form a spatial-temporal cube.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;img src=&quot;/img/4.JPG&quot; alt=&quot;Resize&quot; /&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;This pyramid involves &lt;strong&gt;local information&lt;/strong&gt; in ﬁne-scale layers and more &lt;strong&gt;global structures&lt;/strong&gt; in small-resolution ones.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;With the spatial-temporal cubes, we compute &lt;strong&gt;3D gradient features&lt;/strong&gt; on each of them following “&lt;a href=&quot;https://www.cs.drexel.edu/~kon/publication/LKratz_CVPR09.pdf&quot;&gt;Anomaly Detection in Extremely Crowded Scenes Using Spatio-Temporal Motion Pattern Models&lt;/a&gt;”&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Features are processed separately according to their spatial coordinates. &lt;strong&gt;Only features at the same spatial location in the video frames are used together&lt;/strong&gt; for training and testing.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;em&gt;Learning Combinations on Training Data&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;3D gradient features&lt;/strong&gt; in all frames gathered temporally for training are denoted as &lt;script type=&quot;math/tex&quot;&gt;X=\{x_1, x_2, ..., x_n\} \in R^{p*n}&lt;/script&gt;. Each $x_i$ has $p$ features and there are $n$ $x_i$ in the $X$&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Our goal is to &lt;strong&gt;find a sparse basis combination set&lt;/strong&gt; &lt;script type=&quot;math/tex&quot;&gt;S=\{S_1, S_2, ..., S_K\}&lt;/script&gt; with each $S_i \in R^{p*s}$. Each $S_i$ combines $s$ dictionary basis vectors and each basis vector has $p$ features which correspond to the features in $x_i$. Each $S_i$ belongs to a closed, convex and bounded set, which ensures column-wise unit norm to &lt;strong&gt;prevent over-ﬁtting&lt;/strong&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;Reconstruction Error&lt;/strong&gt;
 	&lt;script type=&quot;math/tex&quot;&gt;t=min_{s,\gamma,\beta}\sum_{j=1}^n\sum_{i=1}^K\gamma_j^i\|x_j-S_i\beta_j^i\|_2^2 \quad s.t. \sum_{i=1}^K\gamma_j^i=1,\gamma_j^i=\{0,1\}&lt;/script&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Each $\gamma_j^i$ indicates whether or not the $i^{th}%$ combination $S_i$ is chosen for data $x_j$ and &lt;strong&gt;only one combination $S_i$ is selected for each $x_j$&lt;/strong&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;$K$ must be small enough&lt;/strong&gt; because a very large $K$ could possibly make the reconstruction error $t$ always close to zero&lt;strong&gt;(Don’t understand)&lt;/strong&gt;, even for abnormal events. However, we want the errors to be larger for abnormal events&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;em&gt;Optimization for Training&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;Problem : Reducing $K$ could increase reconstruction errors $t$&lt;/strong&gt;. And it is not optimal to ﬁx $K$ as well, as content may vary among videos&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;Solution :&lt;/strong&gt;  A maximum representation strategy. It &lt;strong&gt;automatically ﬁnds $K$ while not wildly increasing the reconstruction error $t$&lt;/strong&gt;. In fact, error $t$ for each training feature is upper bounded in our method&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;Updated function&lt;/strong&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;t_j=\sum_{i=1}^K\gamma_j^i \{ \|x_j-S_i\beta_j^i \|_2^2 -\lambda \} \le 0,\quad s.t. \sum_{i=1}^K\gamma_j^i=1,\gamma_j^i=\{0,1\}&lt;/script&gt;

    &lt;ul&gt;
      &lt;li&gt;$\lambda :$  We obtain a set of combinations with a small $K$ by setting a reconstruction error upper bound $\lambda$ uniformly for each $S_i$. If $t_j$ is smaller than $\lambda$, the coding result is with good quality&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;em&gt;Algorithm&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;In each pass, we update only one combination&lt;/strong&gt;, making it represent as many training data as possible&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;This process can &lt;strong&gt;quickly ﬁnd the dominating combinations encoding important and most common features&lt;/strong&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Remaining training cube features that cannot be well represented by this combination are &lt;strong&gt;sent to the next round to gather residual maximum commonness&lt;/strong&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;This process &lt;strong&gt;ends until all training data are computed and bounded&lt;/strong&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;The size of combination $K$ reﬂects how informative the training data are&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;In each pass, we &lt;strong&gt;solve the equation above by interatively update ${S_s^i,\beta}$ and $\lambda$&lt;/strong&gt;&lt;/p&gt;
        &lt;ol&gt;
          &lt;li&gt;&lt;strong&gt;Update ${S_s^i,\beta}$&lt;/strong&gt; :&lt;/li&gt;
        &lt;/ol&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;L(\beta,S_i)=\sum_{j \in \Omega_c}\gamma_j^i \{ \|x_j-S_i\beta_j^i \|_2^2 \}&lt;/script&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;\beta_j^i=(S_i^TS_i)^{-1}S_i^Tx_j&lt;/script&gt;

        &lt;p&gt;(Optimize $\beta$ while ﬁxing $S_i$ for all $\gamma_j^i \neq 0$)&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;S_i=\prod[S_i-\delta_t\bigtriangledown_{S_i}L(\beta,S_i)]&lt;/script&gt;

        &lt;p&gt;( Using &lt;strong&gt;block-coordinate descent&lt;/strong&gt;( &lt;a href=&quot;http://www.jmlr.org/papers/volume11/mairal10a/mairal10a.pdf&quot;&gt;Online learning for matrix factorization and sparse coding&lt;/a&gt; and set $\delta = 1E-4$)&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;&lt;strong&gt;Update $\gamma$&lt;/strong&gt; :&lt;/li&gt;
        &lt;/ol&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\gamma_j^i = \left\{
  \begin{aligned}
  1 \quad &amp; if \quad \|x_j-S_i\beta_j^i \|_2^2 &lt; \lambda ; \\
  0 \quad &amp; otherwise ;\\
  \end{aligned}
  \right . %]]&gt;&lt;/script&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;/img/5.JPG&quot; alt=&quot;Algorithm 1&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;&lt;strong&gt;The algorithm is controlled by $\lambda$, Reducing it could lead to a larger $K$&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;em&gt;Testing&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;With the learned sparse combinations $S = {S_1, …, S_K}$, in the testing phase with new data $x$, we checki f there exists a combination in $S$ ﬁtting the $\lambda$. It can be quickly achieved by checking the least square error for each $S_i$&lt;/li&gt;
    &lt;/ul&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;min_{\beta^i}\|x_j-S_i\beta_j^i \|_2^2 \quad \forall i= 1, ..., K&lt;/script&gt;

    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;optimal solution :&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{\beta^i}=(S_i^TS_i)^{-1}S_i^Tx&lt;/script&gt;

    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Reconstruction error in $S_i$ :&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\|x_j-S_i\beta_j^i \|_2^2 = \|((S_i^TS_i)^{-1}S_i^T-I_p)x\|_2^2=\|R_ix\|_2^2&lt;/script&gt;

    &lt;p&gt;&lt;img src=&quot;/img/6.JPG&quot; alt=&quot;Algorithm 2&quot; /&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;It is noted that the ﬁrst a few dominating combinations represent the largest number of normal event features.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Easy to parallel to achieve $O(1)$ complexity&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Average combination checking ratio $= \frac{The\  number\ of\ combinations\ checked}{The\ total\ number\ K}$&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;Relation to Subspace Clustering&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;experiments&quot;&gt;Experiments&lt;/h2&gt;

&lt;h4 id=&quot;system-settings&quot;&gt;System Settings&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Resize each frame to 3 scales&lt;/strong&gt;: $20*20, 30*40, 120*160$ pixels respectively&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Uniformly &lt;strong&gt;partition each layer to a set of non-overlapping 10×10 patches&lt;/strong&gt; (totaly 208 sub-regions for each frame $\frac{20*30+30*40+120*160}{10*10}=208$ )&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/img/7.JPG&quot; alt=&quot;Patches in 3 scales, each region corresponds to a K&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Corresponding sub-regions in 5 continuous frames are stacked together to form a spatial temporal cube with resolution $10*10*5$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Compute 3D gradient features&lt;/strong&gt; on each cube and concatenate them into a 1500-dimension feature vector&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Reduce the feature vector to 100 dimensions via &lt;strong&gt;PCA&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Normalize&lt;/strong&gt; the reduced feature vector to make it mean 0 and variance 1&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;For each frame, we compute an &lt;strong&gt;abnormal indicator $V$&lt;/strong&gt; by summing the number of cubes in each scale with weights&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;V=\sum_{i=1}^n 2^{n-i}v_i&lt;/script&gt;

    &lt;p&gt;$v_i$ : the number of abnormal cubes in scale $i$, the top scale is with index $1$ while the bottom one is with $n$.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;verification-of-sparse-combinations&quot;&gt;Verification of Sparse Combinations&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Each video contains 208 regions and each region correspond to a cube and there are 6000-12000 features in each sube&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The features are used to &lt;strong&gt;verify the combination model&lt;/strong&gt;. The number of combinations for each region is $K$&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/img/8.JPG&quot; alt=&quot;The distribution of K in 31200 regions from 150 videos&quot; /&gt;
  The mean of $K$ is 9.75 and variance is 10.62, indicating 10 combinations are generally enough in our model&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;说人话&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;假设有一个学习好的$D\in R^{p \times q}$, 稀疏系数$\alpha_i$的0范数小于等于$s$&lt;/p&gt;

    &lt;p&gt;也就是每个样本$x_i$最多能用$s$个字典基来表达。因为要稀疏，显然有$s « q$&lt;/p&gt;

    &lt;p&gt;对于每个$x_i$，测试时都要从$q$个字典基中找出$s$个来表示，要求使得损失函数最小。&lt;/p&gt;

    &lt;p&gt;&lt;strong&gt;&lt;em&gt;因此这种测试方式很花时间（每次都在求解一个优化问题）&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;这篇文章主要解决了效率问题，提出了新的测试方式（训练$D$的方式也随之改变）：&lt;/p&gt;

    &lt;p&gt;预先训练好$K$个稀疏表达$S_1 … S_K$，每个表达$S_i$都由$D$中的$s$个字典基组成&lt;/p&gt;

    &lt;p&gt;测试时，将$x_i$与每个$S_i$计算得到损失函数，选择损失最小的$S_i$即可&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;重点在于得到$K$个$S_i$：&lt;/p&gt;

    &lt;p&gt;设置一个损失函数上限$\lambda$，低于这个上限就认为编码质量好&lt;/p&gt;

    &lt;p&gt;每个周期更新一个$S_i$，使其遍历在之前的周期还未被很好表达的$x_i$（也就是说，不论用什么已获得的$S_i$，该$x_i$的损失函数都超过$\lambda$）。&lt;/p&gt;

    &lt;p&gt;对于每个周期未被很好表达的$x_i$，都留到下一个周期通过新的$S_i$来表达。如此循环直到所有$x_i$都可以被很好的表达。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在每次循环得到新的$S_i$的过程中：&lt;/p&gt;

    &lt;p&gt;目标函数为：
  &lt;script type=&quot;math/tex&quot;&gt;min_{S_i,\gamma,\beta}\sum_{i=1}^K\gamma_j^i ( \|x_j-S_i\beta_j^i \|_2^2 -\lambda ),\quad s.t. \sum_{i=1}^K\gamma_j^i=1,\gamma_j^i=\{0,1\}&lt;/script&gt;&lt;/p&gt;

    &lt;p&gt;&lt;strong&gt;&lt;em&gt;分 2 步解决这个问题&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;更新$S_s^i,\beta$ :&lt;/p&gt;

        &lt;p&gt;(更新 $\beta$ 时固定 $S_i$ 并且所有 $\gamma_j^i \neq 0$)&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;
            &lt;script type=&quot;math/tex; mode=display&quot;&gt;\beta_j^i=(S_i^TS_i)^{-1}S_i^Tx_j&lt;/script&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;script type=&quot;math/tex; mode=display&quot;&gt;S_i=\prod[S_i-\delta_t\bigtriangledown_{S_i}L(\beta,S_i)]&lt;/script&gt;

            &lt;script type=&quot;math/tex; mode=display&quot;&gt;\delta = 1E-4&lt;/script&gt;
          &lt;/li&gt;
        &lt;/ol&gt;

        &lt;p&gt;详情请见&lt;a href=&quot;http://127.0.0.1:4001/2016/09/21/Online-Learning-for-Matrix-Factorization-and-Sparse-Coding/&quot;&gt;Online Learning for Matrix Factorization and Sparse Coding&lt;/a&gt;中的算法1和算法2&lt;/p&gt;

        &lt;p&gt;&lt;img src=&quot;/img/5.JPG&quot; alt=&quot;Algorithm 1&quot; /&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;更新&lt;strong&gt;$\gamma$&lt;/strong&gt; :&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\gamma_j^i = \left\{
  \begin{aligned}
  1 \quad &amp; if \quad \|x_j-S_i\beta_j^i \|_2^2 &lt; \lambda ; \\
  0 \quad &amp; otherwise ;\\
  \end{aligned}
  \right . %]]&gt;&lt;/script&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;测试&lt;/p&gt;

    &lt;p&gt;对于目标函数：
  &lt;script type=&quot;math/tex&quot;&gt;min_{\beta^i}\|x_j-S_i\beta_j^i \|_2^2 \quad \forall i= 1, ..., K&lt;/script&gt;&lt;/p&gt;

    &lt;p&gt;最优解为:
  &lt;script type=&quot;math/tex&quot;&gt;\hat{\beta^i}=(S_i^TS_i)^{-1}S_i^Tx&lt;/script&gt;&lt;/p&gt;

    &lt;p&gt;损失函数可化为：
  &lt;script type=&quot;math/tex&quot;&gt;\|x_j-S_i\beta_j^i \|_2^2 = \|((S_i^TS_i)^{-1}S_i^T-I_p)x\|_2^2=\|R_ix\|_2^2&lt;/script&gt;&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/img/6.JPG&quot; alt=&quot;Algorithm 2&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>icbcbicc</name></author><summary>Abnormal Event Detection at 150 FPS in MATLAB</summary></entry><entry><title>C++ Primer Note 1</title><link href="http://icbcbicc.github.io/2016/07/22/cprimer_note_1/" rel="alternate" type="text/html" title="C++ Primer Note 1" /><published>2016-07-22T00:00:00+08:00</published><updated>2016-07-22T00:00:00+08:00</updated><id>http://icbcbicc.github.io/2016/07/22/cprimer_note_1</id><content type="html" xml:base="http://icbcbicc.github.io/2016/07/22/cprimer_note_1/">&lt;h2 id=&quot;c-primer-4th-edition-notes-chapter-1--2&quot;&gt;C++ Primer 4th Edition Notes Chapter 1 &amp;amp; 2&lt;/h2&gt;

&lt;h3 id=&quot;chapter-1&quot;&gt;chapter 1&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;返回值必须是&lt;code class=&quot;highlighter-rouge&quot;&gt;int&lt;/code&gt;类型&lt;/li&gt;
  &lt;li&gt;返回值0表示&lt;code class=&quot;highlighter-rouge&quot;&gt;main&lt;/code&gt;函数成功执行完毕，非0返回值的含义由各个OS自行定义&lt;/li&gt;
  &lt;li&gt;编译
    &lt;ul&gt;
      &lt;li&gt;Linux: &lt;code class=&quot;highlighter-rouge&quot;&gt;g++ a.cpp -o a&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;Windows: &lt;code class=&quot;highlighter-rouge&quot;&gt;cl -GX a.cpp&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;C++后缀与具体编译器有关：&lt;code class=&quot;highlighter-rouge&quot;&gt;.cc .ccx .cpp .cp .c&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;查看main的返回值
    &lt;ul&gt;
      &lt;li&gt;Linux: &lt;code class=&quot;highlighter-rouge&quot;&gt;echo $?&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;Windows: &lt;code class=&quot;highlighter-rouge&quot;&gt;echo %ERRORLEVEL%&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;iostream
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;cin&lt;/code&gt;: 标准输入&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;cout&lt;/code&gt;: 标准输出&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;cerr, clog&lt;/code&gt;: 标准错误&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c--&quot; data-lang=&quot;c++&quot;&gt;&lt;span class=&quot;cp&quot;&gt;#include&amp;lt;iostream&amp;gt;
&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Enter 2 nums:&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;endl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;nl&quot;&gt;std:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;endl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;&amp;lt;&lt;/code&gt;: 输出操作符，返回左操作数&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;gt;&amp;gt;&lt;/code&gt;: 输入操作符，返回左操作数&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;endl&lt;/code&gt;: 操纵符，可以换行并且flush缓冲区&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;std::cin &amp;gt;&amp;gt; v1 &amp;gt;&amp;gt; v2;&lt;/code&gt;
  可以转换为&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c--&quot; data-lang=&quot;c++&quot;&gt;    &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;std:cout &amp;lt;&amp;lt; v1+v2 &amp;lt;&amp;lt; std::endl;&lt;/code&gt;
可以转换为&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c--&quot; data-lang=&quot;c++&quot;&gt;    &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;endl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;读入未知数目的输入&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c--&quot; data-lang=&quot;c++&quot;&gt;    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    	&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;   
	&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;输入文件结束符
    &lt;ul&gt;
      &lt;li&gt;Linux: &lt;code class=&quot;highlighter-rouge&quot;&gt;ctrl+D&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;Windows: &lt;code class=&quot;highlighter-rouge&quot;&gt;ctrl+Z&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;注释对&lt;code class=&quot;highlighter-rouge&quot;&gt;/* */&lt;/code&gt;不能嵌套&lt;/li&gt;
  &lt;li&gt;在&lt;code class=&quot;highlighter-rouge&quot;&gt;for(int count = 0;count&amp;lt;10;count++)&lt;/code&gt;循环中的&lt;code class=&quot;highlighter-rouge&quot;&gt;count&lt;/code&gt;在循环外不可访问(推荐使用，防止意外访问)&lt;/li&gt;
  &lt;li&gt;use &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt; &amp;gt;&lt;/code&gt; to include standard lib, use &lt;code class=&quot;highlighter-rouge&quot;&gt;&quot; &quot;&lt;/code&gt; top include non-standard lib (personal lib)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;chapter-2&quot;&gt;chapter 2&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;2 kinds of character
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;char&lt;/code&gt;: 8 bits&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;wchar_t&lt;/code&gt;: 16 bits&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Do not use &lt;code class=&quot;highlighter-rouge&quot;&gt;char&lt;/code&gt; as a computational type, it may results in some problems&lt;/li&gt;
  &lt;li&gt;In many circumstances, &lt;code class=&quot;highlighter-rouge&quot;&gt;double&lt;/code&gt; runs much more faster than &lt;code class=&quot;highlighter-rouge&quot;&gt;float&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Usually, &lt;code class=&quot;highlighter-rouge&quot;&gt;long double&lt;/code&gt; is too time-consuming and not neccessary&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;short&lt;/code&gt; may leads to some wrap around false&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;int&lt;/code&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;long&lt;/code&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;short&lt;/code&gt; represent &lt;code class=&quot;highlighter-rouge&quot;&gt;signed *&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;unsigned int&lt;/code&gt; can be simply spelled as &lt;code class=&quot;highlighter-rouge&quot;&gt;unsigned&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;All characters , including all unprintable characters, can be represented as &lt;code class=&quot;highlighter-rouge&quot;&gt;\obbb&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;\xddd&lt;/code&gt;. &lt;code class=&quot;highlighter-rouge&quot;&gt;bbb&lt;/code&gt; are 3 octal numbers and &lt;code class=&quot;highlighter-rouge&quot;&gt;ddd&lt;/code&gt; are 3 hexadecimal numbers.&lt;/li&gt;
  &lt;li&gt;Every string in C++ will be added with an null character(&lt;code class=&quot;highlighter-rouge&quot;&gt;\0&lt;/code&gt;) at the end of the string. For example, &lt;code class=&quot;highlighter-rouge&quot;&gt;&quot;A&quot;&lt;/code&gt; includes an &lt;code class=&quot;highlighter-rouge&quot;&gt;&#39;A&#39;&lt;/code&gt; and a &lt;code class=&quot;highlighter-rouge&quot;&gt;\0&lt;/code&gt;, but &lt;code class=&quot;highlighter-rouge&quot;&gt;&#39;A&#39;&lt;/code&gt; only contains a &lt;code class=&quot;highlighter-rouge&quot;&gt;&#39;A&#39;&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;wide char: &lt;code class=&quot;highlighter-rouge&quot;&gt;&#39;L&#39;&#39;A&#39;&lt;/code&gt;, wide string: &lt;code class=&quot;highlighter-rouge&quot;&gt;&#39;L&#39;&quot;A&quot;&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Concatenate strings(they shoulde be the same kind of string): &lt;code class=&quot;highlighter-rouge&quot;&gt;&quot;A&quot; &quot;B&quot;&lt;/code&gt;. Join wide string and normal string may causes problpems(Undefinded operation)&lt;/li&gt;
  &lt;li&gt;Use &lt;code class=&quot;highlighter-rouge&quot;&gt;\&lt;/code&gt; to split one line into two, but there is no need doing this if you wanna separate a string into more sub-strings. For example:&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c--&quot; data-lang=&quot;c++&quot;&gt;&lt;span class=&quot;s&quot;&gt;&quot;asd&quot;&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;&quot;zxc&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;same&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;with&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;&quot;asd \
zxc&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;All characters(including space or tabs) after the &lt;code class=&quot;highlighter-rouge&quot;&gt;\&lt;/code&gt; in the folowing line will be treated as part of the string, so the indent after &lt;code class=&quot;highlighter-rouge&quot;&gt;\&lt;/code&gt; may be incorrect&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;初始化:
    &lt;ul&gt;
      &lt;li&gt;复制初始化 &lt;code class=&quot;highlighter-rouge&quot;&gt;int val = 1024;&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;直接初始化 &lt;code class=&quot;highlighter-rouge&quot;&gt;int val(1024);&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;这两种初始化方法差别微妙，但是直接初始化语法更加灵活并且高效&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;对内置类型来说，两种初始化几乎没有差别&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;对类型对象来说，有些初始化只能用直接初始化完成。有多个初始化式时不能使用复制初始化（即直接初始化需要多个参数时无法用复制初始化）。
例如：&lt;code class=&quot;highlighter-rouge&quot;&gt;std::string a(4,&#39;9&#39;);&lt;/code&gt; : &lt;code class=&quot;highlighter-rouge&quot;&gt;a = “9999”&lt;/code&gt;
        &lt;ul&gt;
          &lt;li&gt;在函数体外定义的内置类型会自动初始化为0，在函数内定义的内置函数不初始化&lt;/li&gt;
          &lt;li&gt;未初始化的变量事实上都有一个值&lt;/li&gt;
          &lt;li&gt;对于没有提供默认构造函数的类，必须在定义的时候显示地提供初始化式&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;声明与定义
    &lt;ul&gt;
      &lt;li&gt;定义：分配空间，指定初始值。一个程序中，一个变量有且只有一个定义（赋值可有多个）&lt;/li&gt;
      &lt;li&gt;声明：向程序表明变量的类型和名字，变量可声明多次。&lt;/li&gt;
      &lt;li&gt;定义属于声明，但声明不总是定义 
  例如：&lt;code class=&quot;highlighter-rouge&quot;&gt;extern&lt;/code&gt;关键字可用于声明而不定义（也可用于声明并且定义），只有&lt;code class=&quot;highlighter-rouge&quot;&gt;extern&lt;/code&gt;位于函数外部时，才能含有初始化式（声明并且定义）&lt;/li&gt;
      &lt;li&gt;在多个文件中使用的变量都需要有与定义分离的声明。一个文件含有定义，使用这个变量的其他文件则包含声明&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;const&lt;/code&gt;限定符：定义常量。因为常量定义后无法修改，因此定义时必须初始化&lt;/li&gt;
      &lt;li&gt;非&lt;code class=&quot;highlighter-rouge&quot;&gt;const&lt;/code&gt;变量默认为&lt;code class=&quot;highlighter-rouge&quot;&gt;extern&lt;/code&gt;，但要使&lt;code class=&quot;highlighter-rouge&quot;&gt;const&lt;/code&gt;变量能在其他文件中访问，必须显示指定其为&lt;code class=&quot;highlighter-rouge&quot;&gt;extern const&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;引用
    &lt;ul&gt;
      &lt;li&gt;引用是复合类型，是指用其他类型定义的类型。&lt;/li&gt;
      &lt;li&gt;不能定义引用类型的引用&lt;/li&gt;
      &lt;li&gt;引用必须用与该引用 相关联类型的对象（不能是常数） 来初始化（&lt;code class=&quot;highlighter-rouge&quot;&gt;const&lt;/code&gt;引用除外）&lt;/li&gt;
      &lt;li&gt;引用只是一个别名，对引用的所有操作都是作用在该引用绑定的对象上&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;const&lt;/code&gt;引用：可以读取但无法修改，可以绑定其他类型的对象（值可能会发生变化）或者常量&lt;/li&gt;
      &lt;li&gt;将&lt;code class=&quot;highlighter-rouge&quot;&gt;const&lt;/code&gt;对象绑定到非&lt;code class=&quot;highlighter-rouge&quot;&gt;const&lt;/code&gt;引用是非法的&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;typedef&lt;/code&gt;定义类型的同义词
  -例如： &lt;code class=&quot;highlighter-rouge&quot;&gt;typedef int exam_score&lt;/code&gt;，&lt;code class=&quot;highlighter-rouge&quot;&gt;exam_score&lt;/code&gt;就可以当做&lt;code class=&quot;highlighter-rouge&quot;&gt;int&lt;/code&gt;使用&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;枚举(&lt;code class=&quot;highlighter-rouge&quot;&gt;enumeration&lt;/code&gt;)
    &lt;ul&gt;
      &lt;li&gt;关键字: &lt;code class=&quot;highlighter-rouge&quot;&gt;enum&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;例如：&lt;code class=&quot;highlighter-rouge&quot;&gt;enum modes {input,output,append}&lt;/code&gt;。&lt;code class=&quot;highlighter-rouge&quot;&gt;modes&lt;/code&gt;式枚举类型名称。默认第一个枚举成员&lt;code class=&quot;highlighter-rouge&quot;&gt;input&lt;/code&gt;的值为1，后面每个枚举成员的值比前面一个大1。&lt;/li&gt;
      &lt;li&gt;可以定义枚举成员的初值，例如&lt;code class=&quot;highlighter-rouge&quot;&gt;enum modes {input=2,output,append}&lt;/code&gt;，其后每个成员依次加1&lt;/li&gt;
      &lt;li&gt;枚举成员的值可以不唯一。但都是常量，无法修改&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;enum&lt;/code&gt;定义了一个新的类型，可以定义和初始化其中的枚举成员&lt;br /&gt;
  例如： &lt;code class=&quot;highlighter-rouge&quot;&gt;modes delete = append&lt;/code&gt;&lt;br /&gt;
  但只能用枚举成员或者同一枚举类型的其他对象来初始化，不能使用常数&lt;br /&gt;
  例如： &lt;code class=&quot;highlighter-rouge&quot;&gt;modes delete = 3&lt;/code&gt;是错误的&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;class&lt;/code&gt;与&lt;code class=&quot;highlighter-rouge&quot;&gt;struct&lt;/code&gt;唯一区别在于默认访问级别
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;class&lt;/code&gt;：每一个成员都默认为&lt;code class=&quot;highlighter-rouge&quot;&gt;private&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;struct&lt;/code&gt;：每一个成员都默认为&lt;code class=&quot;highlighter-rouge&quot;&gt;public&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;头文件一般包含
    &lt;ul&gt;
      &lt;li&gt;类的定义&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;extern&lt;/code&gt;变量的声明&lt;/li&gt;
      &lt;li&gt;函数的声明&lt;/li&gt;
      &lt;li&gt;由常量初始化的&lt;code class=&quot;highlighter-rouge&quot;&gt;const&lt;/code&gt;变量&lt;/li&gt;
      &lt;li&gt;例如：&lt;code class=&quot;highlighter-rouge&quot;&gt;extern int a = 10;&lt;/code&gt;或者&lt;code class=&quot;highlighter-rouge&quot;&gt;double b;&lt;/code&gt;都属于定义，不应该出现在头文件中（头文件包含在多个源文件中，直接定义容易产生多重定义错误）&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;编译时将&lt;code class=&quot;highlighter-rouge&quot;&gt;#include&amp;lt;头文件&amp;gt;&lt;/code&gt;替换为头文件的内容，因此头文件内的变量声明不用&lt;code class=&quot;highlighter-rouge&quot;&gt;extern&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;设计头文件时应该保证多次包含同一头文件不会引起多次定义，可以通过使用 头文件保护符 让头文件安全&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;预处理器变量
    &lt;ul&gt;
      &lt;li&gt;通常全部大写，在程序中必须唯一&lt;/li&gt;
      &lt;li&gt;使用类名来命名预处理器变量可以避免预处理器变量重名&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;#define&lt;/code&gt;用于指定一个名字为预处理器变量&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;#ifndef&lt;/code&gt;用于检测指定的预处理器变量是否未定义，如果未定义，则处理其后所有指令直到&lt;code class=&quot;highlighter-rouge&quot;&gt;#endif&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;#define&lt;/code&gt;写在&lt;code class=&quot;highlighter-rouge&quot;&gt;#ifndef&lt;/code&gt;与&lt;code class=&quot;highlighter-rouge&quot;&gt;#endif&lt;/code&gt;之间即可保证头文件不被多次包含
&lt;br /&gt;例如：&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c--&quot; data-lang=&quot;c++&quot;&gt;&lt;span class=&quot;cp&quot;&gt;#ifndef TAG
#define TAG
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;...&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;code&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;cp&quot;&gt;#endif&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;</content><author><name>icbcbicc</name></author><category term="C++" /><summary>C++ Primer 4th Edition Notes Chapter 1 &amp;amp; 2</summary></entry><entry><title>Machine Learning (Zhihua Zhou) Notes 01</title><link href="http://icbcbicc.github.io/2016/07/20/machine_learning_zhihua_zhou_notes_01/" rel="alternate" type="text/html" title="Machine Learning (Zhihua Zhou) Notes 01" /><published>2016-07-20T00:00:00+08:00</published><updated>2016-07-20T00:00:00+08:00</updated><id>http://icbcbicc.github.io/2016/07/20/machine_learning_zhihua_zhou_notes_01</id><content type="html" xml:base="http://icbcbicc.github.io/2016/07/20/machine_learning_zhihua_zhou_notes_01/">&lt;h1 id=&quot;machinelearningzhihuazhounotes-01&quot;&gt;Machine_Learning_Zhihua_Zhou_Notes-01&lt;/h1&gt;</content><author><name>icbcbicc</name></author><category term="machine learning" /><summary></summary></entry></feed>
